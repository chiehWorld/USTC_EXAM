# 零基础通关：高级数据库系统复习详解（增强版）

## 第1章：数据库系统导论
**核心：数据库的世界观与架构**

### 1.1 数据模型 (Data Model)
数据模型是数据库的“骨架”。
*   **概念模型**：按**用户**的想法来描述数据。最典型的是 **E-R模型**（实体-关系图）。
    *   *特点*：只有“人”和“事”，不关心怎么存。
*   **逻辑模型**：按**计算机**能理解的逻辑来描述。
    *   **关系模型**（重点）：用二维表来表示。
    *   *层次模型*：像树根一样（IBM IMS系统），一个子节点只能有一个父节点。
    *   *网状模型*：像网一样，一个子节点可以有多个父节点。
    *   *对象模型*：面向对象编程思想，支持继承、多态。
*   **物理模型**：数据在**硬盘**上怎么存（索引、聚簇、分区）。

### 1.2 三级模式与两级映像 (必考)
为了让“改动”不影响“使用”，数据库设计了三层隔离：
1.  **外模式 (External Schema / View)**：**用户层**。
    *   这是用户看到的“局部数据”。比如财务只看到工资表，看不到员工家庭住址。一个数据库可以有N个外模式。
2.  **模式 (Conceptual Schema / Logical Schema)**：**逻辑层**。
    *   这是数据库的“全景图”。定义了所有表、列、类型、约束。**只有一个**。
3.  **内模式 (Internal Schema)**：**物理层**。
    *   定义数据在磁盘怎么存（堆文件还是排序文件？有什么索引？）。**只有一个**。

**两个独立性（解耦）：**
*   **逻辑独立性**：当**模式**改变（加了一列）时，通过修改映像，使**外模式**不变。**结果**：应用程序代码不用改。
*   **物理独立性**：当**内模式**改变（换了更快的硬盘、建了B+树索引）时，通过修改映像，使**模式**不变。**结果**：表结构不用改。

### 1.3 DBMS的组件
*   **查询处理器 (Query Processor)**：负责解析SQL，翻译成代数树，并选择最快的方法执行。
*   **存储管理器 (Storage Manager)**：
    *   **缓冲池管理器**：把磁盘数据读到内存，决定哪些页留着，哪些页写回。
    *   **事务管理器**：保证ACID特性。
    *   **恢复管理器**：断电后负责重启恢复。

---

## 第2章：关系模型与关系数据库
**核心：一切皆表格**

### 2.1 关系模型基础
*   **关系 (Relation)**：一张表。
*   **模式 (Schema)**：表的表头定义 `Students(SID, Name, Age)`。
*   **实例 (Instance)**：表里具体的每一行数据（会随时间变化）。
*   **域 (Domain)**：列取值的约束（如：年龄必须是整数）。

### 2.2 完整性约束 (ICs)
*   **域约束**：规定了每一列（属性）能填什么样的数据，不能填什么样的数据。
*   **键约束**：**超键**与**候选键**（见2.3）。
*   **引用完整性约束 (RIC)**：数据库的一种“防错机制”，用来保证两张表之间的数据关系的真实性。

### 2.3 键 (Key) 的辨析
*   **超键 (Super Key)**：能唯一标识一行（关系中每个元组）的属性子集（**可能会有冗余属性**）。
    *   *例子*：{学号}、{学号, 姓名}、{学号, 姓名, 性别}。只要带了学号，都能唯一标识，都是超键。
*   **候选键 (Candidate Key)**：**最小**的超键（**没有冗余属性**）。
    *   *例子*：{学号} 是候选键。{学号, 姓名} 不是（多了姓名）。
*   **主键 (Primary Key)**：从候选键里选一个作为身份证。
*   **外键 (Foreign Key)**：存的是别的表的主键，用来建立两个关系之间的一个联系（引用完整性约束）。

### 2.4 关系代数 (SQL的数学底座)
**基本运算**：
1.  **选择 ($\sigma$, Select)**：`WHERE`。横向切，挑行。
    *   *例子*：$\sigma_{系别='CS'}$ (选出所有CS系的学生)。
2.  **投影 ($\pi$, Project)**：`SELECT`。纵向切，挑列。
    *   *例子*：$\pi_{姓名}$ (只保留姓名列，去重)。
3.  **并 ($\cup$)**、**交 ($\cap$)**、**差 ($-$)**：集合运算，要求两张表结构相同。
    *   **并 ($\cup$)**：A+B (去重)
    *   **交 ($\cap$)**：A和B都有的
    *   **差 ($-$)**：A里有，B里没的
4.  **笛卡尔积 ($\times$)**：全排列。
    *   *例子*：R(2行) $\times$ S(3行) = 6行。

**高级运算**：
1.  **连接 ($\bowtie$, Join)**：最核心。
    *   $\theta$连接：指定条件的连接。
    *   **自然连接**（最常用）：自动找同名列相等，并去掉重复列。
2.  **除法 ($\div$, Division)**：查询“完成了**所有**...的人”。
    *   *例子1*：
        *   表R(选手, 技能)，表S(技能)。S里有{跳舞, 唱歌}。
        *   $R \div S$ 的结果是：既会跳舞又会唱歌的选手。如果只会跳舞，就被除掉了。
    *   *例子2*：选课表 $\div$ 必修课表 = 选了**所有**必修课的学生。

**其他操作符**：
1.  重命名操作符 (ρ)，其代数表达式为：ρ (R’(A1 -> A1’, …, Ai -> Ai’, …), E)
2.  消除重复运算 $\delta(\mathbf{R_B})$ ，其操作对象可以是包型关系或集合型关系（代价较大，默认不自动消除）。
3.  排序操作 $\boldsymbol{T}_L(\boldsymbol{R})$。该操作用来将关系 $\boldsymbol{R}$ 的所有元组，按 $\boldsymbol{L}$ 所指定方式排序输出。
    *   $\boldsymbol{L}$ 是一个属性表达列表，具有形如 $A_1 [\text{asc}|\text{desc}], A_2 [\text{asc}|\text{desc}], \dots$ 的形式。
4.  分组聚合 $\gamma_L(R)$：先分堆，再计算。
    *   把多行数据按某个特征“捏”在一起，算出一个总数或平均值等。
    *   **例子**：$\gamma_{部门, \text{SUM}(薪水)}$ (按部门分组，算出各部门的总工资)。

### 2.5 关系演算 (Relational Calculus)
**核心：用逻辑公式来描述“我要什么数据”，而不关心“怎么算出来”。**

#### 1. 元组关系演算 (TRC, Tuple Relational Calculus)
*   **基础**：以 **元组（整行数据）** 为变量。SQL语言的设计深受TRC影响。
*   **基本形式**：$ \{ t \mid P(t) \} $
    *   $t$：元组变量（代表结果集中的一行）。
    *   $P(t)$：一个逻辑公式（Formula），$t$必须满足这个公式为真。
*   **公式构成**：
    *   **原子公式**：
        1.  $t \in Relation$：$t$ 是某张表的一行。
        2.  $t.Attr \ op \ c$：$t$ 的某列值满足条件（如 $t.age > 20$）。
        3.  $t.Attr \ op \ s.Attr$：两个元组的属性比较。
    *   **连接词**：$\land$ (与), $\lor$ (或), $\neg$ (非), $\to$ (蕴含)。
    *   **量词**（必考点）：
        *   **$\exists$ (存在量词)**：只要有一个满足即可（对应SQL的 `EXISTS`）。
        *   **$\forall$ (全称量词)**：必须所有都满足（通常转化为 $\neg \exists \neg$ 来理解，即“不存在一个不满足”）。
*   **【应用示例】**：
    *   *查询*：找出等级(rating)大于7的水手信息。
        *   *TRC表达*：$\{ t \mid t \in Sailors \land t.rating > 7 \}$
        *   *解读*：我要一个元组 $t$，首先 $t$ 得是水手表里的行，其次 $t$ 的等级要大于7。
    *   *查询*（涉及连接）：找出预订了103号船的水手姓名。
        *   *TRC表达*：$\{ t.sname \mid t \in Sailors \land \exists r \in Reserves (r.sid = t.sid \land r.bid = 103) \}$
        *   *解读*：我要水手 $t$ 的名字，条件是**存在**一个预订记录 $r$，这个 $r$ 是 $t$ 订的，且订的是103号船。

#### 2. 域关系演算 (DRC, Domain Relational Calculus)
*   **基础**：以 **域变量（列/字段）** 为变量。QBE (Query-By-Example) 语言基于此。
*   **基本形式**：$ \{ <x_1, x_2, ..., x_n> \mid P(x_1, x_2, ..., x_n) \} $
    *   $x_i$：域变量，代表某一个属性的值。
*   **【应用示例】**：
    *   *查询*：找出等级大于7的水手ID、姓名、等级、年龄。
        *   *DRC表达*：$\{ <I, N, T, A> \mid <I, N, T, A> \in Sailors \land T > 7 \}$
        *   *解读*：我要找四个值组成的结果，这四个值构成的行必须属于 Sailors 表，且第三个值(等级T)必须大于7。

#### 3. TRC vs DRC 区别
*   TRC 说：给我那个**行** $t$。
*   DRC 说：给我那几个**值** $<x, y, z>$。

> **复习建议**：
> 1.  **对于考试**：重点掌握 **TRC** 的 $\exists$（存在量词）的使用，因为它对应 SQL 中的连接（Join）和子查询（Exists）。
> 2.  **理解难点**：$\forall$（全称量词）通常用于“查询选修了**所有**课程的学生”这类除法问题。
>       *   逻辑转化公式：$\forall x (P(x)) \equiv \neg \exists x (\neg P(x))$。
>       *   *口语翻译*：要找选了所有课的人 $\rightarrow$ 找一个“不存在一门课他没选”的人。

### 2.5 SQL与数据库编程
*   **SQL执行顺序**：`FROM` (加载表) -> `WHERE` (过滤行) -> `GROUP BY` (分组) -> `HAVING` (过滤组) -> `SELECT` (选列) -> `ORDER BY` (排序)。
*   **ODBC/JDBC**：
    *   这是应用程序（Java/C++）连接数据库的桥梁。
    *   **工作流**：加载驱动 -> 建立连接(Connection) -> 创建语句(Statement) -> 执行SQL -> 处理结果集(ResultSet) -> 关闭连接。

### 2.6 SQL高级操作与扩展关系代数
**核心：掌握SQL如何处理复杂逻辑（集合、嵌套、统计、空值处理）。**

#### 一、集合运算 (Set Operations)
*   **概念**：把两个查询结果集（表）像数学集合一样进行操作。
*   **前提条件**：**并兼容 (Union-Compatible)**。
    1.  列数相同。
    2.  对应列的数据类型兼容（比如都是整数，或都是字符串）。
*   **操作符**：
    1.  **UNION (并)**：$A \cup B$。A和B所有的行，**自动去重**。
        *   *`UNION ALL`*：不去重（保留重复行）。**效率比UNION高**（因为不需要排序去重），考试如果没要求去重，优先写ALL。
    2.  **INTERSECT (交)**：$A \cap B$。同时存在于A和B的行。
    3.  **EXCEPT (差)**：$A - B$。在A中但不在B中的行。（Oracle中叫 `MINUS`）。
*   **【应用示例】**：
    *   查询“既选了数学课又选了英语课的学生学号”。
    *   `SELECT sid FROM 选课 WHERE cname='数学' INTERSECT SELECT sid FROM 选课 WHERE cname='英语'`

#### 二、嵌入查询 (Nested Queries / Subqueries)
**核心：一个查询套在另一个查询里。**

1.  **不相关子查询 (Uncorrelated Subquery)**
    *   **特点**：子查询可以单独执行，跟外层无关。**只执行一次**。
    *   **操作符**：`IN`, `NOT IN`, `ANY`, `ALL`。
    *   **示例**：`SELECT * FROM Student WHERE age > (SELECT AVG(age) FROM Student)`。先把平均年龄算出来（比如20），再查大于20的学生。

2.  **相关子查询 (Correlated Subquery)**（**难点**）
    *   **特点**：子查询依赖外层查询的值。**外层每扫描一行，子查询就要执行一次**（逻辑上）。
    *   **操作符**：`EXISTS`, `NOT EXISTS`。
    *   **执行逻辑**：就像双重 `for` 循环。
    *   **【应用示例】**：查询“选修了 1号课程 的学生姓名”。
        ```sql
        SELECT S.name FROM Student S 
        WHERE EXISTS (SELECT * FROM SC WHERE SC.sid = S.sid AND SC.cid = 1)
        ```
        *   *解释*：拿出一个学生S，去SC表里看看“有没有”（Exists）他的选课记录且是1号课。如果有，这个学生就被选中。
    *   **优化视角**：相关子查询效率通常很低（$O(N^2)$），高级数据库优化器会尝试将其**去相关化 (Decorrelation)**，转换成连接（Join）操作来执行。

#### 三、聚合操作 (Aggregate Operations)
**核心：对一组数据进行统计，变成一个值。**

1.  **聚合函数**：
    *   `COUNT(*)`：数行数（包括NULL）。
    *   `COUNT(列名)`：数该列非NULL值的个数。
    *   `SUM`, `AVG`, `MAX`, `MIN`：求和、平均、最大、最小（都自动忽略NULL）。

2.  **分组 (GROUP BY) 与 过滤 (HAVING)**
    *   **执行顺序**：`WHERE` (过滤原始行) $\to$ `GROUP BY` (分组) $\to$ **聚合函数计算** $\to$ `HAVING` (过滤分组结果)。
    *   **铁律**：出现在 `SELECT` 后面，但没有用聚合函数包裹的列，**必须**出现在 `GROUP BY` 后面。
    *   **【应用示例】**：查询“平均分大于80分的**每个系**的系名”。
        ```sql
        SELECT DeptName, AVG(Score) 
        FROM Student 
        GROUP BY DeptName 
        HAVING AVG(Score) > 80
        ```
        *   *错题警示*：不能写 `WHERE AVG(Score) > 80`，因为WHERE执行时还不知道平均分是多少。

#### 四、外连接操作 (Outer Join Operations)
**核心：解决“连接时因为匹配不上而丢失数据”的问题。**
在关系代数中，自然连接($\bowtie$) 会丢弃不匹配的行。外连接通过**填补NULL**来保留这些行。

1.  **左外连接 (Left Outer Join, $\sqsupset$)**
    *   **含义**：保留**左表**的所有行。如果右表没匹配上，右边的列填 `NULL`。
    *   *场景*：列出所有学生及其选课情况（没选课的学生也要列出来，课程显示NULL）。
2.  **右外连接 (Right Outer Join, $\sqsubset$)**
    *   **含义**：保留**右表**的所有行。
3.  **全外连接 (Full Outer Join, $\sqsupset\kern-3pt\sqsubset$)**
    *   **含义**：保留**两边**的所有行。不管谁没匹配上，都保留，补NULL。
    *   *场景*：对比两张表差异时常用。

> **复习Tips：**
> *   **考试坑点**：`COUNT(col)` 和 `COUNT(*)` 的区别（前者不统计NULL）；`WHERE` 和 `HAVING` 的区别（前者不能跟聚合函数）。
> *   **计算题关联**：在外排序和连接算法（第6章）中，聚合操作（Aggregate）通常通过**排序**（Sort）或**哈希**（Hash）来实现。比如计算 `GROUP BY`，通常先把数据按分组列排序，然后扫一遍就能算出结果。

---

## 第3章：数据库表结构设计
**核心：设计不冗余、不异常的表**

### 3.1 ER模型与EER模型
*   **ER三要素**：实体（方框）、属性（椭圆）、关系（菱形）。
*   **弱实体 (Weak Entity)**：自己活不了，必须依附别人。
    *   *例子*：`员工`和`家属`。没有员工，家属表里的数据没意义。画图用**双边框**。
*   **EER (扩展ER)**：
    *   **特化/泛化**：前者类似于面向对象的继承，后者是前者的逆过程。
        *   *例子*：`人`是超类，`学生`和`老师`是子类（ISA关系）。
    *   **聚集 (Aggregation)**：把一个“关系”看作一个“实体”再次参与关系。
> **【PPT chap3p11】**
>    *   **圆圈里的 "d" (Disjoint, 不相交)** 意味着 **互斥**。
>    *   **圆圈里的 "o" (Overlapping, 重叠)** 意味着 **可重叠**。
>    *   **粗黑线 (Total Specialization, 完全特化)**：
>        *   这通常表示**强制性**。即**必须**属于其中的一类，不能属于“其他”类型。
>    *   **细线 (Partial Specialization, 部分特化)** 表示 **非强制性**。
>    *   **弧线（看起来像一个小半圆或小碗）**
>        *   代表的是**定义谓词 (Defining Predicate)** 或简单来说就是**分类条件**。
>        *   这表示这些子类是 **“基于谓词定义的子类” (Predicate-defined Subclasses)**，也就是“自动分类的规则”。
>        *   那个弧线的意思就是：**“当属性值等于……”**。
>            *   **没有弧线**：通常意味着子类成员需要人工手动指定（用户定义）。
>            *   **有弧线**：意味着子类成员是根据父类里的某个**属性值**自动划分的。

### 3.2 ER转关系模式 (Mapping)
*   **1:1**：外键随便放，或者合并成一张表。
*   **1:N**：把“1”那头的主键，放到“N”那头做外键。
    *   *原因*：一个班级有多个学生。在学生表里加“班级ID”最合适。
*   **M:N**：**必须新建表**。
    *   *例子*：学生选课。新表`选课(学号, 课程号, 成绩)`。主键是`(学号, 课程号)`。
*   **多值属性**：新建一张表。
    *   *例子*：一个人有多个电话。建表`电话(人ID, 电话号码)`。

### 3.3 规范化 (Normalization)
**目的**：消除数据冗余，避免插入/删除/更新异常。

1.  **模式分解 (解决冗余问题)**：
    *   **无损连接**：拆开后还能拼回去，数据不多不少。
        *   *定理*：拆成R1, R2。如果 $R1 \cap R2$（公共属性）是 R1 或 R2 的键，则无损。
    *   **依赖保持**：拆分后，原来的规矩（FD）在小表里还能检查，不需要跨表检查。

2.  **函数依赖 (FD)**：$X \to Y$。在表里，X的值一样，Y的值就必须一样。
    *   **自反**：大推小（(学号,姓名) -> 学号）。
    *   **增广**：两边加一样（若 A->B，则 AC->BC）。
    *   **传递**：链式推导（A->B, B->C，则 A->C）。
    *   **合并规则 / 加法规则 (IR4, Union Rule)**
        *   **公式**：若 $X \to Y$ 且 $X \to Z$，则 $X \to YZ$。
        *   **含义**：如果X能决定Y，也能决定Z，那么X就能决定Y和Z的组合。
        *   **【应用场景】**：在计算**闭包 ($X^+$)** 时最常用。
            *   *例子*：已知 `学号->姓名`，`学号->班级`。
            *   *推导*：可以直接写出 `学号->(姓名, 班级)`。如果没有这个规则，你得写好几步推导。
    *   **分解规则 / 投影规则 (IR5, Decomposition Rule)**
        *   **公式**：若 $X \to YZ$，则 $X \to Y$ 且 $X \to Z$。
        *   **含义**：如果X能决定一个组合，那么它也能决定组合里的每一个部分。
        *   **【应用场景】**：在**判断范式**和**模式分解**时最常用。
            *   *例子*：已知 `身份证号->(省份, 城市)`。
            *   *推导*：显然 `身份证号->省份` 成立，`身份证号->城市` 也成立。这可以帮我们把大依赖拆成小依赖来检查2NF/3NF。

3.  **范式升级之路**：
    *   **1NF**：格子不能拆。不能一个格子里填“张三, 李四”。
    *   **2NF**：**消除非主属性对码的部分依赖**。
        *   *坏例子*：PK=(学号, 课号)。字段有(姓名)。(学号)->姓名。姓名只依赖主键的一部分。
        *   *解法*：拆表。
    *   **3NF**：**消除非主属性对码的传递依赖**。
        *   *坏例子*：PK=学号。字段有(系名, 系主任)。学号->系名->系主任。
        *   *解法*：把(系名, 系主任)拆出去。
    *   **BCNF**：**所有决定因素都是超键**。
        *   比3NF严。只要箭头左边的属性不是键，就不行。

---

## 第4章：数据存储和组织管理
**核心：硬盘很慢，怎么存读得快？**

### 4.1 磁盘原理
*   **访问时间** = **寻道时间** (最慢，磁头机械移动) + **旋转延迟** (等盘片转过来) + **传输时间**。
*   **优化原则**：尽量**顺序读写**（减少寻道），尽量一次读一块（Block）。
*   **存取时间公式**：
    $Time = \text{Seek Time} + \text{Rotational Delay} + \text{Transfer Time}$
    *   **寻道时间 (Seek Time)**：磁头移动到目标磁道的时间（通常题目会给平均值）。
    *   **旋转延迟 (Rotational Delay)**：
        *   平均旋转延迟 = $\frac{1}{2} \times \text{旋转一周的时间}$。
        *   旋转一周时间 = $60 / \text{转速(RPM)}$ 秒。
    *   **传输时间 (Transfer Time)**：
        *   读取数据量 / 数据传输率。
        *   或者：$\frac{\text{要读的扇区数}}{\text{每磁道总扇区数}} \times \text{旋转一周时间}$。

> **【例 4.1】【PPT chap4p9】** **磁盘参数与容量计算**
>
> **题目**：设有一含3个盘片的硬盘，共有4个面（有效记录面），转速为4500转/分钟。盘面有效记录区的内、外径分别为10cm、30cm。记录位密度为250位/mm，磁道密度为8道/mm。每个磁道有16扇区，每扇区512字节。
> 
> **计算**：
> 1.  **磁盘总磁道数**：
>     *   单面有效宽度 = $(30 - 10) / 2 = 10 \text{ cm} = 100 \text{ mm}$。
>     *   单面磁道数 = $100 \text{ mm} \times 8 \text{ 道/mm} = 800 \text{ 道}$。
>     *   总磁道数 = $4 \text{ (面)} \times 800 = 3200 \text{ 道}$。
> 2.  **格式化容量**：
>     *   容量 = 总磁道数 $\times$ 每磁道扇区数 $\times$ 扇区字节数
>     *   $= 3200 \times 16 \times 512 = 26,214,400 \text{ Bytes} \approx 25 \text{ MB}$。
> 3.  **平均数据传输速率**：
>     *   转速 = 4500 转/分 = 75 转/秒。
>     *   每磁道容量 = $16 \times 512 = 8192 \text{ Bytes}$。
>     *   速率 = $8192 \times 75 = 614,400 \text{ B/s} \approx 600 \text{ KB/s}$。

> **【例 4.2】【PPT chap4p10】** **磁盘I/O存取时间计算**
>
> **题目**：某硬盘含4个盘片，8个盘面。每个盘面有8192个磁道，每磁道256个扇区，每扇区512字节。块大小为4096字节。磁盘转速3840转/分。磁头起落1次1毫秒，每移过500个磁道另加1毫秒。试计算读写一个块的平均时间。
> 
> **基础参数计算**：
> *   **容量**：$8 \times 8192 \times 256 \times 512 = 8 \text{ GB}$。
> *   **块结构**：每磁道块数 = $(256 \times 512) / 4096 = 32$ 块。每块占 $4096/512 = 8$ 个扇区。
> *   **转速**：$3840/60 = 64 \text{ 转/秒}$ $\Rightarrow$ 转一圈需 $1/64 \text{ s} \approx 15.6 \text{ ms}$。
>
> **存取时间详解**：
> 1.  **平均寻道时间 (Seek Time)**：
>     *   磁头移动时间模型：$1 \text{ ms (起落)} + (\text{移动磁道数}/500) \times 1 \text{ ms}$。
>     *   平均随机寻道距离通常取总磁道数的 $1/3$。
>     *   $\text{Seek} \approx [1 + (8192/500)] / 3 \approx 5.8 \text{ ms}$。
> 2.  **平均旋转延迟 (Rotational Latency)**：
>     *   平均等待半圈：$15.6 \text{ ms} / 2 = 7.8 \text{ ms}$。
> 3.  **传输时间 (Transfer Time)**：
>     *   读一个块（8个扇区）所需时间。
>     *   总扇区256个，转一圈15.6ms。
>     *   $\text{Transfer} = 15.6 \times (8/256) \approx 0.5 \text{ ms}$。
> 4.  **总时间**：$5.8 + 7.8 + 0.5 = 14.1 \text{ ms}$。

### 4.2 RAID技术 (磁盘阵列)
*   **RAID 0 (条带化)**：数据切碎分到多块盘。**读写最快**，坏一块全完。
*   **RAID 1 (镜像)**：两块盘存一样的。**最安全**，写得慢（要写两份），贵。
*   **RAID 4 (奇偶校验)**：块条带化 + **专用校验盘**。读快，**写有瓶颈** (每次写都要更校验盘)。
    *   **校验更新公式**：$P_{new} = D_{old} \oplus D_{new} \oplus P_{old}$ (4次I/O: 2读2写)
*   **RAID 5**：RAID 4的改进，校验块交替分布。
*   **RAID 6**：RAID 5的扩展，数据块分布在各个硬盘上（类似于 RAID 0 和 RAID 5）
    *   **校验**：与 RAID 5 只计算一个校验位（P）不同，RAID 6 计算**两个独立的奇偶校验位**（通常标记为 **P** 和 **Q**）。
        *   **P 校验**：通常使用异或（XOR）运算。
        *   **Q 校验**：通常使用更复杂的算法（如 Reed-Solomon 编码或伽罗华域算法）计算。
    *   **分布**：这两个校验数据（P和Q）**轮流分布**在阵列中的所有磁盘上，而不是存储在专门的校验盘上（避免了 RAID 4 的热点问题）。
    *   **允许同时损坏 2 块硬盘**：这是 RAID 6 相比 RAID 5 最大的优势。
    *   **数据恢复**：
        *   如果坏 1 块盘：利用 P 校验或 Q 校验均可恢复（类似 RAID 5）。
        *   如果坏 2 块盘：利用 P 和 Q **建立联立方程组**，求解出丢失的数据。
*   **RAID 10**：先镜像再条带化。又快又安全，最贵。

### 4.3 页与记录组织
*   **定长记录**：每行长度固定。直接算位置：$Base + i \times Length$。
*   **变长记录**：使用 **槽页结构 (Slotted Page)**（高频考点）。
    *   *结构*：页头存信息，记录从页尾往中间堆，页头后有 **指针数组（槽）** 指向记录。
    *   *优点*：记录在页内移动（如碎片整理）时，外部引用的RID（页号+槽号）不用变，只改槽里的指针。
*   最为通用：采用特殊字符结尾实现具有变长字段的记录组织。

### 4.4 记录管理技术
*   **行溢出**：一条记录太大，一页放不下。
    *   *解法*：跨页存储。本页存指针，指向下一页（溢出页）。
*   **大对象 (LOB)**：存图片视频。通常存在专门的LOB存储区，表里只存指针。

---

## 第5章：数据库索引技术
**核心：快速定位数据的目录**

### 5.1 索引分类
*   **聚集索引 (Clustered)**：数据文件的排列顺序（物理存储顺序）和索引一样。
    *   **最快**。
    *   适合范围查询。
*   **非聚集索引 (Unclustered)**：索引有序，数据乱序。
    *   叶子节点存的是指向数据的指针（RID）。
*   **稠密索引**：每个记录都有一个索引项。
*   **稀疏索引**：每页只有一个索引项（前提是数据必须有序）。
*   **多级索引**：索引文件本身作为一般顺序数据文件。
    *   三级及以上级索引，不如直接使用B树。
*   主索引：以主码作为搜索键的索引。
    *   典型代表：聚集索引。
    *   一张表只能有一个（通常是主键）。
*   辅助索引：搜索键不是主码，或者说，索引的顺序与数据文件的物理顺序不一致的索引。
    *   典型代表：非聚集索引。
    *   一张表可以有多个辅助索引。

> **SQL 索引创建语法**
>
> ```sql
> CREATE [UNIQUE] [CLUSTERED|NONCLUSTERED]    
> INDEX index_name USING {BTREE|HASH}
> ON table_name (col1 [ASC|DESC], col2...);
> ```
>
> **语法说明：**
> *   `[]`：表示**可选项**（例如 `UNIQUE` 可写可不写）。
> *   `{}`：表示**必选项**（例如必须在 `BTREE` 和 `HASH` 中选一个）。
> *   `...`：表示可以有多个列。

### 5.2 B+树 (B+ Tree)
*   **结构**：
    *   **非叶节点**：只存路标（Key），不存数据。
    *   **叶子节点**：存所有数据（或指针）。叶子之间有**双向链表**相连。
*   **为什么用B+树？**：
    *   树矮胖（层数少，IO少）。
    *   支持**范围查询**（找到起点后顺着链表读即可）。
    *   性能稳定。
*   **批量加载 (Bulk Loading)**：
    *   如果表里已经有1亿条数据，一条条Insert建索引太慢。
    *   *方法*：1. 对数据排序；2. 直接铺满叶子节点；3. 向上生成父节点。
*   **插入**：节点满 (元素数=m) 时分裂。
    *   **叶子分裂**：中间元素上推，但在叶子中**保留**副本。
    *   **非叶子分裂**：中间元素**上推**，不在原节点保留。
*   **删除**：节点少于半满 ($\lceil m/2 \rceil$) 时合并或借位。
    *   **合并**：父节点中的索引项下移，和兄弟合并。
    *   **借位**：从兄弟借一个，父节点索引项更新为借位后的新分界值。
*   重复键处理：当某个键值（如“男/女”或“年龄”）重复率极高时，单个**叶节点 (Leaf Node)** 空间有限，无法容纳该键值对应的所有记录指针 (RID)。
    *   溢出页法：在叶节点中只保留一个指针，指向专门存储重复键的“溢出页”。
    *   连续节点法：像处理普通键一样，让重复键的数据跨越并占据**连续的多个**叶节点。
    *   唯一化法：
        *   原理：将 `RID` (记录ID) 并入搜索键。
        *   效果：Key 变为 `(Original_Key, RID)`。由于 RID 唯一，**逻辑上消除了重复键**。
*   键压缩处理：只保留键值的**前缀**部分，而非存储整个键值，以减少索引项长度。
    *   安全规则：保持语义。压缩不能破坏 B+ 树的有序性。
    *   算法逻辑：寻找最短的前缀 $K'$，使其满足分界条件：
        $$ \text{Max}(\text{LeftSubtree}) < K' \le \text{Min}(\text{RightSubtree}) $$
    *   示例：
        *   左子树最大值：`Fish`，右子树原始键：`Fisher`
        *   压缩为 `F` -> 错误，因为 `Fish` > `F`。
        *   压缩为 `Fishe` -> 正确，`Fish` < `Fishe` <= `Fisher`。

### 5.3 散列索引 (Hash)
*   **原理**：Hash(Key) = 桶地址。
*   **局限**：只能查“等于”，不能查“大于小于”。
*   **动态散列**（解决数据变多桶不够用的问题）：
    *   **可扩展散列 (Extendible Hashing)**：使用一个**目录 (Directory)** 指向桶。桶满了，目录翻倍，分裂桶。**特点**：有全局深度和局部深度。
    *   **线性散列 (Linear Hashing)**：不需要目录。按顺序（0号、1号...）分裂桶，而不是谁满谁分裂。
*   **特点**：使用**目录 (Directory)**，目录深度 Global Depth (GD)。桶深度 Local Depth (LD)。
*   **插入规则**：
    1.  如果桶没满，直接放。
    2.  如果桶满了，且 $LD < GD$：桶分裂，LD+1，目录指向更新（不用翻倍）。
    3.  如果桶满了，且 $LD = GD$：**目录翻倍**，GD+1，桶分裂，LD+1，重新哈希。
*   全局位深度 ($d$)：
    *   控制**目录结构**。目录有 $2^d$ 个条目。
    *   代表整个哈希表目前的“分辨率”。
*   局部位深度 ($\ell$)：
    *   控制**桶内数据**。桶内记录的哈希后缀在 $\ell$ 位上相同。
    *   决定**指针数量**：一个桶会被 $2^{d-\ell}$ 个目录项同时指向。

### 5.4 空间索引与位图索引
*   **位图索引 (Bitmap)**：
    *   适用：列的基数小（如性别、状态）。
    *   原理：用010101串表示。男：1001...；女：0110...。
    *   优点：位运算（AND, OR）极快，统计快。
*   **位图压缩**：在建立位图索引时，如果属性的取值非常多（基数大），生成的位图向量会非常稀疏且庞大。为了节省存储空间并提高计算效率，必须对位图进行压缩。
    *   *原理*：该技术的核心思想是**游程编码 (Run-Length Encoding, RLE)** 的变种。它不直接存储 0 和 1，而是存储“连续 0 的个数”（记为 $i$）。
    *   为了解决直接二进制编码带来的歧义（例如无法区分两个短游程和一个长游程），采用了一种特殊的 **前缀码 (Prefix Code)** 机制。
    *   **编码规则**：对于一个数值 $i$（代表 0 的个数）：
        1.  **计算长度 $j$**：令 $j = \lceil \log_2 i \rceil$（即 $i$ 的二进制长度）。
        2.  **生成前缀**：写 $j-1$ 个 `1`，后面跟一个 `0`。
        3.  **生成后缀**：写 $i$ 的二进制表示（长度为 $j$）。
        4.  **特殊情况**：
            *   若 $i=0$，编码为 `00`。
            *   若 $i=1$，编码为 `01`。
    *   **编码示例 ($i=13$)：**
        *   $j = \lceil \log_2 13 \rceil = 4$
        *   前缀：$4-1=3$ 个 `1` 加一个 `0` $\rightarrow$ `1110`
        *   后缀：13 的二进制 $\rightarrow$ `1101`
        *   **结果**：`1110 1101`
    *   **解码规则**：解码是编码的逆过程。读取位流时，先通过前缀确定长度 $j$，再读取后续 $j$ 位还原数值。
    *   解码示例：`11101101001011`
        1.  **读取第一段**：
            *   读前缀：`1110` $\rightarrow$ 遇到 0 停止。有 3 个 1，所以 $j-1=3 \Rightarrow j=4$。
            *   读后缀：读取接下来的 4 位 `1101`。
        *   还原数值：$1101_2 = \mathbf{13}$。
        *   *剩余串*：`001011`
        2.  **读取第二段**：
            *   读前缀：`00` $\rightarrow$ 特殊规则，直接还原为 $\mathbf{0}$。
            *   *剩余串*：`1011`
        3.  **读取第三段**：
            *   读前缀：`10` $\rightarrow$ 有 1 个 1，所以 $j-1=1 \Rightarrow j=2$。
            *   读后缀：读取接下来的 2 位 `11`。
            *   还原数值：$11_2 = \mathbf{3}$。
        4.  最终解码出的游程序列为：13, 0, 3
    *   压缩位图的运算：当需要对两个压缩位图进行逻辑运算（如 AND/OR）时，**不需要完全解压**成原始的 0/1 串。只需“一次处理一个段”，交替解码并对其游程进行对齐运算。
    *   运算示例：
        *   **向量 A** (`00110110`) 解析：
            *   `00` $\rightarrow$ **0**
            *   `110110` $\rightarrow$ 前缀 `110` ($j=3$), 后缀 `110` ($6$) $\rightarrow$ **6**
            *   *序列 A*: 0, 6
        *   **向量 B** (`11011111101101`) 解析：
            *   `110111` $\rightarrow$ 前缀 `110` ($j=3$), 后缀 `111` ($7$) $\rightarrow$ **7**
            *   `11101101` $\rightarrow$ 前缀 `1110` ($j=4$), 后缀 `1101` ($13$) $\rightarrow$ **13**
            *   *序列 B*: 7, 13
        *   **运算逻辑**：计算机读取序列 A 的 (0, 6) 和序列 B 的 (7, 13)，通过逻辑判断重叠部分来生成结果向量 C，而无需在内存中展开成包含数百万个 0 的长位图。
*   **（多维）空间索引**：
    *   **R树 (R-Tree)**：B+树的高维版。用最小外接矩形 (MBR) 框住空间对象。

---

## 第6章：关系操作符赋值
**核心：SQL底层的算法实现**

### 6.1 语法分析树
*   树节点类型：
    *   原子类：属词法成份，相当于语言编译器产生的token。原子节点是没有子节点的叶节点。
    *   语法类：相似作用的查询子成份族名称,用角括号括起。
*   语法分析树展示了数据库如何“理解”SQL语句：
    1. 它识别出这是一个查询 (Query)。
    2. 它将查询拆解为三个主要部分：要找什么 (SELECT)，从哪找 (FROM)，什么条件 (WHERE)。
    3. 它递归地将条件拆解为更小的原子单元（比如将 AND 拆分为左右两个等式），直到不能再拆分为止（到达原子节点）。

### 6.2 外部排序
*   当内存放不下数据时，怎么排序？
*   **归并排序**：
    *   Phase 1：读入内存能装下的块，内部排序，写回磁盘（形成Runs）。
    *   Phase 2：多路归并。同时读入N个Runs的头部，选最小的写出。
*   多阶段归并排序 
    *   核心代价 (IO)：
        *   **基本原理**：每个排序阶段都需要读、写整个文件各 1 次。
        *   **单阶段代价**：$2M$ 次 I/O（$M$ 为文件总页数）。
        *   **总代价**：$2M \times \text{阶段数}$。
    *   优化策略：利用缓存 ($B$ 页)。为了降低总代价，必须**减少阶段数**。方法是利用内存缓冲区 $B$ 增加归并的路数。
        *   **初始阶段**：生成更大的初始有序子文件（每个大小为 $B$ 页）。
        *   **归并阶段**：利用 $B$ 个页进行 **$(B-1)$ 路归并**（而非默认的 2 路）。
        *   **通用阶段数公式**：$\lceil \log_{B-1} M \rceil + 1$。
    *   两阶段排序：当内存缓冲区足够大时，排序可以在两个阶段内完成。
        *   **实施条件**：$B > \sqrt{M}$ （即子文件总数 $\lceil M/B \rceil \le B-1$）。
        *   **过程**：
            *   第 1 阶段：生成 $\lceil M/B \rceil$ 个有序子文件。
            *   第 2 阶段：一次性将所有子文件归并完毕。
        *   **总代价**：**$4M$ 次 I/O**。

### 6.3 投影与消除重复的两种实现算法
**这两种算法的核心目标都是处理关系代数中的 $\delta(\Pi_{attributes}(R))$ 操作，即先只保留需要的列（投影），再去掉重复的行。**

#### 1. 基于排序的算法 (Sort-based)
*   **核心思想**：通过排序让相同的元组“聚在一起”，然后简单地扫描一遍即可剔除重复项。
*   **执行步骤**：
    1.  **扫描与投影**：读取原表 $R$，剔除不需要的列，生成临时文件（大小为 $T$ 页）。
    2.  **排序**：以保留的属性为键，对临时文件进行排序（这是开销最大的一步）。
    3.  **扫描去重**：读取排序后的结果，比较相邻元组，丢弃重复值。
*   **代价量级**：$O(M \log M)$ (主要取决于排序的代价)。

#### 2. 基于散列的算法 (Hash-based)
*   **核心思想**：利用哈希函数将相同的元组分发到同一个“桶”中，然后在内存中对每个桶单独去重。
*   **执行步骤**：
    1.  **划分阶段 (Partitioning)**：读取原表 $R$，对投影属性进行哈希，将元组分发到 $B-1$ 个输出缓冲区（写入磁盘形成子桶）。
    2.  **去重阶段**：依次读取每个子桶到内存，利用内存哈希表消除重复元组。
*   **内存条件**：内存缓冲区必须足够大，即 $B \ge \sqrt{M}$ (确保划分出的子桶能一次放入内存)。
*   **总代价**：$M + 2T$
    *   $M$：读取原表。
    *   $2T$：写出子桶 ($T$) + 读回子桶 ($T$)。

#### 3. 二者对比
*   **代价比较**
    *   **前提**：当内存缓冲区足够大（满足 $B > \sqrt{T}$）时。
    *   **结论**：两种方法的总代价**完全相同**，都是 **$M + 2T$** 次 I/O。
        *   ($M$ 为扫描原表，$2T$ 为读写临时文件的开销)。
*   **内存要求比较**
    *   **基于排序 (Sorting)**：
        *   要求 $B \approx \sqrt{T}$ 即可保证在**两阶段**内完成。
        *   性能稳定，不受数据值分布影响。
    *   **基于散列 (Hashing)**：
        *   理论上要求 $B > \sqrt{T}$ (假设哈希划分均匀)。
        *   **风险**：如果发生**数据倾斜 (Skew)**（即某个桶的数据特别多），则可能需要**比 $\sqrt{T}$ 更大的内存**才能容纳最大的子桶。
*   **最终结论**：尽管两者 I/O 代价相近，但在实践中**排序方法通常更优**，理由是：
    *   **结果有序**：排序法的输出结果天然是有序的（这对后续操作很有利）。
    *   **稳定性强**：排序法没有“哈希冲突”或“数据倾斜”导致内存溢出的风险。
    *   **CPU 开销**：哈希计算通常比比较操作更消耗 CPU。

### 6.4 连接算法 (Join Algorithms)
假设 R 连接 S，R表较小（M页），S表较大（N页）。
1.  **嵌套循环 (Nested Loop)**
    *   **Block Nested Loop (BNLJ)**：内存里读入一大块R，然后扫描一遍S。
        *   *代价*：$M + \frac{M}{BlockSize} \times N$。
2.  **索引嵌套循环 (Index Nested Loop)**
    *   如果S表上有索引。读R的一行，去S的索引里查。
    *   *代价*：$M + R_{rows} \times \text{IndexSearchCost}$。
3.  **排序归并连接 (Sort-Merge Join)**
    *   先把R和S都排好序，然后指针一起往下走。
    *   *优点*：如果数据本身有序（有聚集索引），这是最快的。
4.  **散列（哈希）连接 (Hash Join)**
    *   **Phase 1 分区**：用Hash函数把R和S都打散到k个桶里（R1-S1, R2-S2...）。
    *   **Phase 2 探测**：对每一对桶，把小的加载到内存构建Hash表，扫描大的去匹配。
    *   *代价*：$3(M+N)$。

---

## 第7章：查询处理与优化
**核心：让数据库自动选择最快路径**

### 7.1 查询赋值计划
*   **定义与核心概念**：
    *   **查询赋值计划（执行计划）**：它是对 SQL 查询的一种过程化表达。
    *   **本质**：一棵**扩展的关系代数树**。
    *   **特征**：不仅包含逻辑操作（如选择、投影、连接），还**标注**了具体的实现细节（如：使用文件扫描还是索引扫描、使用排序归并连接还是哈希连接）。
*   **计划树的结构**：
    *   **节点**：代表关系代数操作符。
    *   **标注 (Annotations)**：描述了该操作符具体的存储读取方式和执行算法（例如：“文件扫描”、“排序归并连接”）。
    *   **叶节点**：通常对应数据库中的基本关系（表）。
    *   **数据流**：数据从叶节点向上流动，经过各层操作处理，最终在根节点生成结果。
*   **流水线方式赋值**：
    *   **机制**：上层操作直接“消费”下层操作产生的元组，**不存储中间结果**。
    *   **优势**：避免创建和读取临时关系文件，**大幅节省磁盘 I/O**，效率通常较高。
    *   **适用**：大多数高效查询的首选方式。

### 7.2 逻辑查询优化（启发式规则）
**口诀：早过滤，少搬运**
1.  **下推选择**：先把不用的行过滤掉，把大表变小表。
2.  **下推投影**：先把不用的列过滤掉，减小数据宽度。
3.  **结合律应用**：先连小表，再连大表，避免产生过巨大的中间临时表。

### 7.3 物理查询优化
1.  **代价估算**：
    *   **选择率 (Selectivity)**：满足条件的行数占总行数的比例。
        *   `id = 1`：选择率 $\approx 1/N$。
        *   `age > 20`：选择率 $\approx (Max-20)/(Max-Min)$。
2.  **计划枚举**：
    *   **左深树 (Left-deep Tree)**：优化器一般只考虑左深树结构（即连接树向左倾斜）。
    *   *原因*：适合**流水线 (Pipelining)** 执行。右子树是基表，左子树是上一步的结果，算出一行结果立马可以和下一个表连接，不需要把中间结果写硬盘。

---

## 第8章：事务并发控制
**核心：多个人同时改数据，如何不乱？**

### 8.1 事务ACID
*   **A (Atomicity)**：原子性。Undo Log负责。
*   **C (Consistency)**：一致性。代码逻辑和约束负责。
*   **I (Isolation)**：隔离性。锁机制负责。
*   **D (Durability)**：持久性。Redo Log负责。

### 8.2 （死锁预防）可串行化
*   冲突可串行化
    *   这是数据库系统中最常用的判断标准，它关注的是操作的**顺序冲突**。
    *   **什么是“冲突可串行化”？**
        *   如果一个混乱的调度，可以通过**交换那些“不冲突”的操作顺序**，最终变形成一个整整齐齐的串行调度（比如 T1 全部做完再做 T2），那它就是冲突可串行化的。这意味着它是安全的。
    *   **检测方法（优先图）**
        1.  把每个事务画成一个圈（节点）。
        2.  如果 T1 的某个操作和 T2 的某个操作**冲突**，且 T1 在 T2 **之前**发生，就画一条箭头从 T1 指向 T2（表示 T1 必须排在 T2 前面）。
        3.  **判定定理**：画完后，看看图里**有没有环（圈）**。

*   视可串行化 (View Serializability)
    *   这是一个比冲突可串行化 **更弱（包含范围更广）** 的概念。
    *   有些调度画图有环，但实际上它的执行结果也是对的。
    *   **核心思想：结果看起来一样就行**
        *   它不关心中间过程怎么交换，只关心大家 **“看到的”** 和 **“留下的”** 数据是不是和串行执行一样。
    *   **三个判断条件（视等价）**：
        1.  **读初值相同**：大家读到的原始数据版本必须一样。
        2.  **读写来源相同**：如果 S 里 T2 读的是 T1 写的数据，S' 里也得是这样。
        3.  **最终写相同**：最后是谁把数据 A 写进数据库的，在两个调度里必须是同一个人。
    *   二者对比：
        *   冲突可串行化的子集。
        *   数据库通常只实现**冲突可串行化**的检测，检查视可串行化成本太高了。

### 8.3 并发问题
*   **脏读**：读了没提交的数据。
*   **不可重复读**：读了两次，中间被别人改了。
*   **幻读**：读了两次，中间被别人插入了新行（多出来了）。

### 8.4 封锁协议
*   **严格两阶段封锁 (Strict-2PL)**：
    *   写锁必须等到事务**提交/回滚**后才释放。
    *   *作用*：防止**级联回滚**（一个事务挂了，不用把别人也拖下水）。
*   **两阶段封锁 (2PL)**：
    *   **阶段1**：拼命加锁，不许解锁。
    *   **阶段2**：拼命解锁，不许加锁。
    *   *作用*：保证**可串行化**（逻辑正确）。但可能死锁。

### 8.5 死锁处理
*   **预防死锁**
    *   **Wait-Die (等待-死亡)**：弱势等待者，非抢占。新事务要么等，要么自杀。
    *   **Wound-Wait (伤害-等待)**：强势等待者，抢占。新事物要么抢锁，要么等。
*   **死锁检测（等待图）**：用来记录当前所有事务等待关系的一张有向图。
    *   **节点 (Nodes)**：图里的每一个点代表一个**正在运行的事务** (比如 $T_1, T_2, T_3$)。
    *   **边 (Edges)**：图里的箭头代表**等待关系**。
        *   如果 **$T_i \to T_j$**（有一条箭头从 $T_i$ 指向 $T_j$）：
        *   意思是：**$T_i$ 想要申请一把锁，但这把锁目前正被 $T_j$ 拿着。** 所以 $T_i$ 必须等待 $T_j$ 释放锁才能继续执行。
    *   **死锁情况**：**图中出现了回路（环 / Cycle）**。
*   方法对比：
    *   死锁预防更易实现。
    *   死锁不频繁时，死锁处理更实用。

### 8.6 并发处理
*   **基于有效确认（乐观并发控制）**
    *   这种机制假设冲突很少发生，所以让事务先跑，最后提交时再检查有没有冲突。
    *   **时间轴与图表画法**
        *   **三个阶段（符号含义）**：
            *   `|` **(Start/开始)**：读阶段开始。事务开始执行，读取数据，在私有内存中修改，**不**写回数据库。
            *   `×` **(Validation/确认)**：确认阶段开始。系统检查该事务是否与刚刚提交的其他事务有冲突。
            *   `○` **(Finish/完成)**：写阶段完成。如果确认通过，把私有内存的修改真正写入数据库；如果没通过，回滚。
        *   **集合定义**：
            *   **RT(T)** (Read Set)：事务 T 读过的数据集合。
            *   **WT(T)** (Write Set)：事务 T 修改过的数据集合。
    *   **判定规则**：确保事务T在确认时，没有读到“脏数据”，也没有覆盖别人的新数据。
        *   假设我们要验证事务 **T**，我们需要看在 T 执行期间，有没有其他事务 **U** 完成了。
            *   **情况 1：完全不重叠**
                *   如果 U 在 T 开始之前就彻底结束了。
                *   **判定**：绝对安全，无需检查。
            *   **情况 2：串行重叠 (U 在 T 的读阶段完成了)**
                *   **规则**：检查 **WT(U) $\cap$ RT(T)** 是否为空。
                *   **解释**：U 改过的数据，T 读到了吗？如果 T 读到了 U 修改的数据，但 T 读的时候 U 还没写进去（因为 T 是在私有内存读旧值），那 T 就读了错误的老数据。
            *   **情况 3：并发重叠 (U 和 T 的确认/写阶段重叠)**
                *   *图1中的 T 和 V*（假设 V 也要验证）：
                *   **规则**：除了检查 **WT(U) $\cap$ RT(T)**，还得检查 **WT(U) $\cap$ WT(T)**。
                *   **解释**：既不能读错，也不能两个人同时写同一个数据导致覆盖。
*   **基于时间戳排序**
    *   这种机制给每个事务发一个时间戳TS，早来的（TS小）优先，必须遵守先来后到的规则。
    *   图表与表格画法
        *   冲突场景图：
            *   **横轴**：数据对象（X）。
            *   **纵轴/箭头**：表示操作发生的时间顺序。
            *   **虚线**：表示逻辑上的依赖关系（谁应该在谁前面）。
            *   **TS**：事务开始的时间。
        *   **执行过程表**：
            *   **列**：分为两部分。
                *   左边列：事务及其时间戳 (T1, T2, T3...)。
                *   右边列：数据项及其状态 (A, B, C...)。
            *   **数据项状态**：
                *   **RT (Read Timestamp)**：**最后一次**读这个数据的事务的时间戳。
                *   **WT (Write Timestamp)**：**最后一次**写这个数据的事务的时间戳。
            *   **行**：按时间顺序发生的操作步骤。
    *   **判定规则**：**晚辈（大TS）不能做长辈（小TS）已经做完的事的逆操作；晚辈写的字，长辈不能无视。**
        *   假设当前事务是 **T**，时间戳为 **TS(T)**，操作对象是 **X**。
        *   **A. 读操作规则 (T 想读 X)**
            *   **检查**：看 `WT(X)`。
            *   **判定**：
                *   如果 **TS(T) < WT(X)**：说明有一个比 T **年轻**（时间戳更大）的事务已经修改了 X。T 此时去读，读到的是未来的数据（或者 T 本该读旧数据，但旧数据已经被覆盖了）。
            *   **结果**：**拒绝 (Abort/Restart)**。即图2(a)“过晚读”。
            *   否则：**允许**。并更新 `RT(X) = max(RT(X), TS(T))`。
        *   **B. 写操作规则 (T 想写 X)**
            *   **检查 1**：看 `RT(X)`。
                *   如果 **TS(T) < RT(X)**：说明有一个比 T **年轻**的事务已经读了 X。如果 T 现在才写，那个年轻事务刚才读的就是错的（它本该读到 T 写的值）。
                *   **结果**：**拒绝 (Abort/Restart)**。即图2(c)“过晚写”。
            *   **检查 2**：看 `WT(X)`。
                *   如果 **TS(T) < WT(X)**：说明有一个比 T **年轻**的事务已经写了 X。T 的修改已经过时了。
            *   **结果**：
                *   普通处理：拒绝。
                *   **托马斯写规则 (Thomas Write Rule)**：**忽略本次写**。既然更有权威（更新）的人已经写了，T 的这次写虽然过时，但跳过它不会影响数据最终的正确性（最终值还是年轻事务写的那个）。

>**【两种并发处理技术的总结对比】**
>
>| 特性 | 有效确认 (Validation / OCC) | 时间戳排序 (Timestamp Ordering) |
>| :--- | :--- | :--- |
>| **什么时候检查?** | **最后** (提交/确认阶段) | **立刻** (每次读写操作发生时) |
>| **时间轴画法** | 关注 Start, Validation, Finish 三个点 | 关注 TS 与 RT/WT 的数值大小对比 |
>| **判定依据** | 读写集合 (Read/Write Sets) 的交集 | 事务时间戳与数据项时间戳的大小 |
>| **适用场景** | 读多写少，冲突极少的系统 | 需要严格顺序，冲突较多的系统 |

>**【PPT chap8p52】三种并发控制方法需要的额外存储空间代价对比**
>
>| 并发控制方式 | 需要的辅助存储空间情况 |
>| :--- | :--- |
>| **封锁** | 需要增加锁表存储空间，锁表空间与被封锁的 DB 对象个数成正比。 |
>| **时间戳** | 简单实现时：每个 DB 对象要维护读/写时间戳和提交位，不管是否被写过。这可能需要很大的额外存储空间。<br><br>更精细实现：将最早活跃事务以前的所有时间戳统一按 0 或 -∞ 处理而不记录它们，并按类似锁表那样，将最近被访问过的相关对象时间戳记录在一张专门的表中。 |
>| **有效确认** | 对当前活跃事务以及少量几个已提交的更早事务：记录每个事务启动/确认/完成时间戳，以及每个事务的读写元素集。<br><br>该方法的一个潜在问题是，事务的写集合必须在写发生之前知道（这可能需要先扫描一次事务的所有动作）。 |

---

## 第9章：数据库恢复技术
**核心：Crash Recovery**

### 9.1 WAL (预写日志)
*   **原子性**保证：在数据页写回磁盘之前，先把对应的日志写回磁盘。
*   **持久性**保证：事务提交时，先把事务相关日志持久化。

### 9.2 LSN
1. LSN (Log Sequence Number) —— 日志序列号
   *   **含义**：日志文件中每一条记录的**唯一编号**（ID）。
   *   **特征**：单调递增。LSN 越大，代表动作发生得越晚。
   *   **作用**：它是日志记录的“地址”，数据库通过 LSN 来定位具体的某一步操作。
2. prevLSN (Previous LSN) —— 前驱 LSN
   *   **含义**：指向**同一个事务**中**上一条**日志记录的 LSN。
   *   **作用**：它像一条链子，把同一个事务的所有操作倒序串联起来。
   *   **场景**：在 **撤销（Undo）** 时，系统通过 `prevLSN` 从后往前回溯，找到该事务到底做了哪些操作，从而一步步撤销。
3. lastLSN —— 最后一条 LSN
    *   **含义**：存储在**事务表（Transaction Table）**中。它记录了某个**活跃事务**产生的**最新**一条日志记录的 LSN。
    *   **作用**：它是回溯的起点。当需要撤销某个事务时，系统先去事务表里查它的 `lastLSN`，找到最后一步操作，然后沿着 `prevLSN` 往回找。
4. recLSN (Recovery LSN) —— 恢复 LSN
    *   **含义**：存储在**脏页表（Dirty Page Table）**中。当一个页从“干净”变成“脏”（被修改且未写回磁盘）时，记录下**导致它变脏的那第一条日志的 LSN**。
    *   注意：只要这个页还在内存里没刷盘，无论后面又被修改了多少次，`recLSN` 保持不变（始终是第一次变脏时的那个 LSN）。
    *   **作用**：它是 **重做（Redo）** 的起点。它告诉系统：“从这个 LSN 开始，这个页的数据可能还没写到磁盘上，你得检查一下是否需要重做。”
5. undonextLSN —— 下一个待撤销 LSN
    *   **含义**：只出现在 **CLR（补偿日志记录）** 中。当系统撤销（Undo）了一条更新日志（假设该日志的 LSN 为 X，且 X 的 `prevLSN` 为 Y）时，会写一条 CLR。这条 CLR 的 `undonextLSN` 会被设为 **Y**。
    *   **作用**：**防止死循环**。如果在恢复过程中再次崩溃，系统重启后看到 CLR，就知道：“噢，LSN X 已经撤销过了，下一个该去处理 LSN Y 了”。这样就跳过了已经撤销的操作。
6. **关键点总结：**
    *   `prevLSN` 让你知道**上一条在哪**。
    *   `undonextLSN` 让你在遇到 CLR 时知道**下一步跳到哪**（防止重复撤销）。
    *   `recLSN` 让你在重做时知道**从哪开始**。

### 9.3 ARIES算法
1.  **分析 (Analysis)**：
    *   从最近的Checkpoint往后看。
    *   搞清楚谁没做完（**活跃事务表 ATT**）。
    *   搞清楚哪些页可能脏了（**脏页表 DPT**）。
2.  **重做 (Redo)**：无论事务是提交了还是失败了，都要把数据库恢复到**崩溃发生那一瞬间**的状态（包括脏页的内容）。
    *   **起点**：扫描**脏页表**，找到所有脏页中**最小的 recLSN**。从这个位置开始正向扫描日志。
    *   **逻辑**：对于日志中的每一条更新记录（假设涉及页 P，日志 LSN 为 L）：
        1.  如果页 P 不在脏页表中 $\rightarrow$ 说明早已刷盘，**跳过**。
        2.  如果页 P 在脏页表中，但 `recLSN > L` $\rightarrow$ 说明这条日志太老了，页 P 是在后面才变脏的，这条日志的效果肯定在磁盘上了，**跳过**。
        3.  如果以上都不满足，读取磁盘上的页 P，检查页面的 `pageLSN`（页面上记录的最后修改 LSN）：
            *   如果 `pageLSN >= L` $\rightarrow$ 说明磁盘上的数据已经是最新的，**跳过**。
            *   如果 `pageLSN < L` $\rightarrow$ 说明磁盘数据旧了，**执行重做 (Redo)**，再次应用修改。
    *   **总结**：Redo 保证了持久性，确保所有只要写了日志的操作，最终都能体现在数据页上。
3.  **撤销 (Undo)**：
    *   **目标**：把崩溃时还没来得及提交的“失败者事务”（Loser Transactions），统统回滚，消除它们的影响。
    *   **起点**：从日志的**最末尾**开始，反向扫描。
    *   **对象**：在分析阶段被列入“活跃事务表”的所有事务（即崩溃时还没 Commit 的事务）。
    *   **逻辑**：
        1.  拿到所有失败事务的 `lastLSN`。
        2.  选取其中最大的 LSN，假设是记录 U。
        3.  如果 U 是一个**更新记录 (Update)**：
            *   执行**逆操作**（比如原操作是 +10，现在就 -10）。
            *   写一条 **CLR (补偿日志)** 到日志末尾。
            *   CLR 的 `undonextLSN` 指向 U 的 `prevLSN`。
        4.  如果 U 是一个 **CLR**：
            *   说明之前已经撤销过某步了。直接跳跃！
            *   下一个要处理的 LSN = 该 CLR 的 `undonextLSN`。
        5.  如果 U 是事务开始记录：
            *   该事务撤销完毕。
        6.  重复上述过程，直到所有失败事务都彻底回滚。
    *   **总结**：Undo 保证了原子性，确保未提交的事务就像没发生过一样。

---

## PostGIS 的基础操作、空间关系和索引原理
针对**填空题**的考点，可以概括为以下四个核心方面：

1.  **基础几何类型与函数**：
    *   PostGIS 遵循 **OGC**（开放地理空间信息联盟）标准。
    *   核心几何类型包括：**Point**（点）、**Linestring**（线串）、**Polygon**（多边形）以及它们的集合（如 MultiPolygon）。
    *   常用获取属性的函数：**ST_GeometryType**（类型）、**ST_SRID**（空间参考ID）、**ST_AsText**（转文本）、**ST_AsGeoJSON**（转GeoJSON）。
    *   常用计算函数：**ST_Length**（线长）、**ST_Area**（面积）。

2.  **空间关系判断（重点）**：
    *   **ST_Equals**：判断两个几何图形是否在空间上相等。
    *   **ST_Intersects**：判断是否**相交**（最常用，共享任何空间即为真）。
    *   **ST_Disjoint**：判断是否**不相交**（与 Intersects 相反）。
    *   **ST_Contains** 与 **ST_Within**：判断**包含**与**在...内部**的关系（两者互为反义）。
    *   **ST_Touches**：判断**接触**（仅边界相交，内部不相交）。

3.  **距离与空间连接**：
    *   **ST_Distance**：计算两点间的精确距离（浮点数）。
    *   **ST_DWithin**：判断是否在**指定距离（半径）内**（常用于缓冲区查询，支持索引加速，比直接算距离更高效）。
    *   **空间连接**：利用空间关系函数（如 ST_Contains）作为 SQL 中 **JOIN ... ON** 的连接条件。

4.  **空间索引与维护（必考）**：
    *   索引结构：PostGIS 使用 **R-Tree** 结构，PostgreSQL 中通过 **GiST**（通用搜索树）实现。
    *   索引原理：索引存储的是几何体的 **Bounding Box**（边界框/矩形），查询时采用“**两遍法**”（先粗筛边界框，再精算几何体）。
    *   操作符：**&&** 运算符用于测试边界框是否重叠。
    *   数据库维护：**ANALYZE** 命令用于更新统计信息；**VACUUM** 命令用于回收未使用的存储空间（清理死元组）。

**一句话总结（考前速记）：**
熟记 **ST_Intersects**、**ST_Contains**、**ST_DWithin** 等核心函数名；知道索引类型是 **GiST**，原理是 **R-Tree** 和 **边界框**；维护命令是 **VACUUM ANALYZE**。