#### **习题 4.2：磁盘基本参数与性能**

**【题目解读】** 我们要研究一个具体的硬盘，它的物理参数如下：
1.  **结构**：有 5 个盘片，每个盘片有两面（双面）。$\rightarrow$ **知识点：总面数（磁头数）= 5 × 2 = 10 个**。
2.  **密度**：
    *   每个面有 2,000 个磁道（同心圆）。
    *   每个磁道有 50 个扇区（圆弧段）。
    *   每个扇区存 512 字节（Bytes）。
3.  **速度**：
    *   **寻道时间**（磁头移动到正确磁道的时间）：平均 10ms。
    *   **转速**：5,400 rpm（Revolutions Per Minute，每分钟转数）。

**【解题过程】**

**问题 (1)：计算每个盘面的格式化容量和整个磁盘的格式化容量。**
*   **详细计算**：
    1.  **单面容量**：
        $$2000 \text{ (磁道)} \times 50 \text{ (扇区/磁道)} \times 512 \text{ (字节/扇区)}$$
        $$= 100,000 \times 512 = 51,200,000 \text{ 字节 (Bytes)}$$
        $$51,200,000 \div 1024 \div 1024 \approx \mathbf{48.8 \text{ MB}}$$

    2.  **总容量**：
        $$49 \text{ MB (单面)} \times 10 \text{ (面)} = \mathbf{490 \text{ MB}}$$

**问题 (2)：如果转速为 5,400 rpm，计算最大旋转延迟和平均旋转延迟。**

*   **知识点：旋转延迟 (Rotational Latency)**
    *   磁头到了磁道上方，还得等数据（扇区）转到磁头底下。
    *   **最大延迟**：运气最差，刚转过去，要等整整一圈。
    *   **平均延迟**：平均运气，只要等半圈。

*   **详细计算**：
    1.  **先算出转一圈要多久**：
        *   5400 rpm = 每分钟转 5400 圈。
        *   每秒转数 = $5400 \div 60 = 90$ 圈/秒。
        *   转一圈的时间 = $1 \text{ 秒} \div 90 \approx 0.0111 \text{ 秒}$。
        *   换算成毫秒(ms) = **11.1 ms**。

    2.  **最大旋转延迟** = 转一圈的时间 = **11.1 ms**。

    3.  **平均旋转延迟** = 转半圈的时间 = $11.1 \div 2 = \mathbf{5.55 \text{ ms}}$。

**问题 (4)：如果每个磁盘块占 2 个扇区，估算传输一个块的平均时间。**

*   **知识点：磁盘存取时间公式**
    *   **总时间 = 寻道时间 + 旋转时间 + 传输时间**
    *   **寻道**：找磁道（题目给的）。
    *   **旋转**：等扇区（用平均值）。
    *   **传输**：磁头读数据划过扇区的时间。

*   **详细计算**：
    1.  **寻道时间**：题目直接给了 **10 ms**。
    2.  **旋转时间**：用上面算的平均值 **5.55 ms**。
    3.  **传输时间**：
        *   转一圈（读完所有50个扇区）需要 11.1 ms。
        *   我们要读 **2个扇区**（一个块）。
        *   时间占比 = $2 \div 50 = 0.04$ (即4%)。
        *   传输时间 = $11.1 \text{ ms} \times 0.04 \approx \mathbf{0.44 \text{ ms}}$。
    4.  **总时间**：
        $$10 \text{ (寻道)} + 5.55 \text{ (旋转)} + 0.44 \text{ (传输)} = 15.99 \text{ ms} \approx \mathbf{16 \text{ ms}}$$

#### **习题 4.3：数据在磁盘上的布局与读取**

**【题目解读】**
*   **文件背景**：有一个关系文件，包含 **100,000 个元组**，每个元组 **100 字节**。
*   **存储规则**：磁盘块大小 = **1,024 字节**。**不允许跨块存储**。

**【解题过程】**

**问题 (1)：每个块可存放多少个元组？存储整个文件需要多少个块？**
*   **详细计算**：
    1.  **单块容量**：1024 字节。
    2.  **单个元组**：100 字节。
    3.  **直接除**：$1024 \div 100 = 10.24$。
    4.  **取整**：因为不能切开存，所以小数舍去。每个块只能存 **10 个元组**（剩下的24字节是碎渣，浪费了）。
    5.  **总块数**：
        *   总元组：100,000 个。
        *   每块存：10 个。
        *   需要的块数 = $100,000 \div 10 = \mathbf{10,000 \text{ 个块}}$。

**问题 (2)：估算顺序扫描该关系文件需要的总时间。**

*   **知识点：顺序扫描的理解（逻辑连续但物理随机）**。每个块的读取都需要经历一次完整的“寻道+旋转+读取”周期。这通常被用作**最坏情况**的估算，或者当文件碎片化严重时的估算。

*   **详细计算（基于图片答案的逻辑）**：
    1.  **单个块的读取时间**：即我们在 4.2(4) 中计算出的 **16 ms** (0.016秒)。
    2.  **总块数**：10,000 个。
    3.  **总时间**：
        $$10,000 \text{ (块)} \times 16 \text{ (ms/块)} = 160,000 \text{ ms} = \mathbf{160 \text{ 秒}}$$
        $$160 \div 60 \approx \mathbf{2.7 \text{ 分钟}}$$

**问题 (3)：如果该磁盘的各盘面上磁头能并行读/写数据，且磁盘数据是按可能的优化方式安排（按柱面连续），执行文件排序扫描需多少时间？**

*   **知识点：并行读写**：读一个柱面不需要移动磁头（寻道），且因为10个头同时读，转一圈就能把这个柱面上所有盘面的数据都读完！

*   **详细计算**：
    1.  **计算一个柱面能存多少数据**：
        *   一个柱面包含 **10 个磁道**（因为有10个面）。
        *   每个磁道有 50 个扇区。
        *   题目说 1 个块 = 2 个扇区 $\rightarrow$ 每个磁道有 $50 \div 2 = 25$ 个块。
        *   **一个柱面的容量** = $10 \text{ (面)} \times 25 \text{ (块/面)} = \mathbf{250 \text{ 个块}}$。

    2.  **计算文件需要占多少个柱面**：
        *   文件总共 10,000 个块。
        *   需要柱面数 = $10,000 \div 250 = \mathbf{40 \text{ 个柱面}}$。

    3.  **计算时间**：
        *   在这种“超级优化”模式下，读取一个完整的柱面只需要磁盘**转一圈**（因为10个头并行，转一圈所有面的数据都进来了）。
        *   **读一个柱面（转一圈）的时间** = 11.1 ms (即 0.011s)。
        *   我们需要读 40 个柱面。
        *   **总时间** = $40 \text{ (柱面)} \times 0.011 \text{ (秒/柱面)} = \mathbf{0.44 \text{ 秒}}$。

#### **习题 4.8：RAID 4 校验值计算**

**【题目解读】**
*   **RAID 4**：一种磁盘阵列，把数据分开存在 D1, D2, D3, D4 上，用一个专门的盘 P 存校验码。
*   **规则**：P 的值是 D1, D2, D3, D4 对应位置数据的 **异或 (XOR)** 结果。
*   **异或口诀**：**奇数个1 $\rightarrow$ 1；偶数个1 $\rightarrow$ 0**。

**【解题过程】**

**数据：**
D1: `01010110`
D2: `11000000`
D3: `00111011`
D4: `11111011`

**计算 P (按列竖着看)：**
1.  第1位：0, 1, 0, 1 $\rightarrow$ 两个1 (偶数) $\rightarrow$ **0**
2.  第2位：1, 1, 0, 1 $\rightarrow$ 三个1 (奇数) $\rightarrow$ **1**
3.  第3位：0, 0, 1, 1 $\rightarrow$ 两个1 (偶数) $\rightarrow$ **0**
4.  第4位：1, 0, 1, 1 $\rightarrow$ 三个1 (奇数) $\rightarrow$ **1**
5.  第5位：0, 0, 1, 1 $\rightarrow$ 两个1 (偶数) $\rightarrow$ **0**
6.  第6位：1, 0, 0, 0 $\rightarrow$ 一个1 (奇数) $\rightarrow$ **1**
7.  第7位：1, 0, 1, 1 $\rightarrow$ 三个1 (奇数) $\rightarrow$ **1**
8.  第8位：0, 0, 1, 1 $\rightarrow$ 两个1 (偶数) $\rightarrow$ **0**

**答案 (1)：** `01010110`

#### **习题 4.9：RAID 6 数据恢复**

> #### 【存疑】课本解释
> 
> #### 1. 核心逻辑：矩阵就是方程组
> 
> 书中的 $3 \times 7$ 矩阵是解题的唯一钥匙。
> *   **行 (Row)**：代表一个校验方程（或者叫一个 RAID 4 组）。
> *   **列 (Column)**：代表一块磁盘。
> *   **数字 1**：表示该列对应的磁盘**参与**该行的校验计算。
> *   **数字 0**：表示该列对应的磁盘**不参与**。
> 
> 根据书上的矩阵，我们可以直接写出**三个核心方程**（设 $\oplus$ 为异或运算）：
> 
> *   **第一行 (对应冗余盘 5)**：
>     *   1号、2号、3号、5号位置是 `1`。
>     *   **方程 ①**：$D_1 \oplus D_2 \oplus D_3 = P_5$
>     *   *(也可以写成 $D_1 \oplus D_2 \oplus D_3 \oplus P_5 = 0$)*
> 
> *   **第二行 (对应冗余盘 6)**：
>     *   1号、2号、4号、6号位置是 `1`。
>     *   **方程 ②**：$D_1 \oplus D_2 \oplus D_4 = P_6$
> 
> *   **第三行 (对应冗余盘 7)**：
>     *   1号、3号、4号、7号位置是 `1`。
>     *   **方程 ③**：$D_1 \oplus D_3 \oplus D_4 = P_7$
> 
> #### 2. 书中提到的“规律特点”解读
> 
> 1.  **“数据盘对应的列至少各有 2 个 1”**：
>     *   这意味着每一块数据盘（1-4号）都至少参与了两个方程。
>     *   **考试意义**：如果坏了一块数据盘，你至少有两条路（两个方程）可以把它算回来。如果方程里涉及的其他盘也坏了，还有备用。
> 
> 2.  **“冗余盘对应的列只有单个 1”**：
>     *   这意味着 5、6、7 号盘各自只负责一个方程，互不干涉。
>     *   **考试意义**：5号盘坏了只影响方程①，6号坏了只影响方程②。
> 
> 3.  **“每个行中...恰好构成一个 RAID 4/5 级”**：
>     *   这就是告诉你计算方法就是**异或 (XOR)**。
> 
> #### 3. 实战：如何用这个“官方逻辑”做题（以题 4.9 为例）
> 
> **步骤一：列出所有受影响的方程**
> *   **方程 ①**：涉及 $D_1, D_2, D_3, P_5$。
>     *   坏了 $D_1$。其他 $D_2, D_3, P_5$ 都是好的。
>     *   **结论**：可以用这个方程恢复 $D_1$！
>     *   计算：$D_1 = D_2 \oplus D_3 \oplus P_5$ (即利用 2, 3, 5号盘恢复)。
> 
> *   **方程 ②**：涉及 $D_1, D_2, D_4, P_6$。
>     *   坏了 $D_1$。其他 $D_2, D_4, P_6$ 都是好的。
>     *   **结论**：也可以用这个方程恢复 $D_1$！
>     *   计算：$D_1 = D_2 \oplus D_4 \oplus P_6$ (即利用 2, 4, 6号盘恢复)。
> 
> *   **方程 ③**：涉及 $D_1, D_3, D_4, P_7$。
>     *   坏了 $D_1$ **和** $P_7$。
>     *   **结论**：这行有两个未知数，废了，**不能**用来恢复 $D_1$。但是，一旦 $D_1$ 被上面的方程恢复了，这个方程就可以用来算出 $P_7$。
> 
> **步骤二：写出答案**
> 根据上面的分析，对应书上的逻辑：
> 1.  **恢复 1号盘**：观察矩阵，发现第二行（方程②）中，除了 1 号盘坏了，其他的（2, 4, 6）都活着。所以利用 2#、4#、6# 盘的数据异或得到 1#。
>     *(注：第一行也可以用，利用 2#, 3#, 5# 恢复 1#)*
> 2.  **恢复 7号盘**：7号盘是校验盘。等 1# 盘数据恢复后，直接利用方程 ③ ($D_1 \oplus D_3 \oplus D_4$) 重新计算出 7# 盘的数据。
> 
> #### 总结（考试必背）
> 1.  **看矩阵**：把矩阵的每一行看作一个**异或公式**。
> 2.  **找好行**：如果让你恢复某个坏盘（比如X），就在矩阵里找X那一列是 `1` 的行。
> 3.  **排除法**：检查这些行里，有没有**其他**坏盘也对应 `1`。
>     *   如果有其他坏盘，这一行（方程）就不能用。
>     *   如果这一行只有X是坏的，其他都是好的，**这就是解题的路径**。
> 4.  **写结果**：该行中所有为 `1` 的其他盘，异或起来就是结果。

#### **习题 5.2：B+树的综合演练**

考虑图 5.21 所示的阶数 **m=4** 的 B+树索引。（注：$m=4$ 意味着每个节点最多有 4 个指针，最多 **3 个键值**）。

#### 预备分析：B+树参数确认
*   **阶数 (Order) $m = 4$**
*   **根节点**：至少2个子节点。
*   **内部节点 (非叶节点)**：
    *   子节点数：最多 $m+1 = 5$，最少 $\lceil (m+1)/2 \rceil$ (通常定义) 或按讲义 $\lfloor m/2 \rfloor + 1 = 3$。
    *   **关键字数 (Keys)**：最多 $m=4$，最少 $3-1=2$。
*   **叶节点 (Leaf Nodes)**：
    *   数据项数：最多 $m = 4$，最少 $\lfloor (m+1)/2 \rfloor = \lfloor 5/2 \rfloor = 2$。

#### (1) 标示插入数据项 9* 之后的 B+树，并指出读写页数

**操作步骤：**
1.  **查找**：从根节点 [50] 开始，小于50走左边。进入节点 [8, 18, 32, 40]。
2.  **定位叶子**：$8 \le 9 < 18$，沿着 8 和 18 之间的指针找到叶节点 [8\*, 10\*]。
3.  **插入**：在叶节点 [8\*, 10\*] 中插入 9\*。
4.  **检查约束**：插入后叶节点变为 [8\*, 9\*, 10\*]。包含3个元素。
    *   最大容量是4，未溢出，无需分裂。

**读写页数统计**：读页数 (3页)，写页数 (1页)。

**结果树变化**：仅叶节点 [8, 10] 变为 [8, 9, 10]，其余不变。

#### (2) 给出在原树中删除数据项 8* 之后的 B+树，并指出读写页数

**操作步骤：**
1.  **查找与删除**：找到叶节点 [8\*, 10\*]，删除 8\*。
2.  **检查下溢 (Underflow)**：
    *   删除后叶节点变为 [10\*]。
    *   元素数量为1，小于最小限制2。发生下溢。
3.  **处理下溢 (借键/重分配)**：
    *   检查**左兄弟** [1\*, 2\*, 5\*, 6\*]：有4个元素 (满)。
    *   检查**右兄弟** [18\*, 27\*]：有2个元素 (最小)。
    *   **策略**：因为左兄弟有富余，优先从左兄弟**借**一个最大的元素 (6\*)。
4.  **借键操作**：
    *   左兄弟 [1\*, 2\*, 5\*, 6\*] 移出 6\*。变为 [1\*, 2\*, 5\*]。
    *   当前节点 [10\*] 接收 6\*。变为 [6\*, 10\*]。
5.  **更新父节点索引**：
    *   原父节点中分隔这两个叶子的关键字是 8。
    *   现在右边叶子的最小关键字变成了 6。
    *   将父节点中的 **8** 更新为 **6**。

**读写页数统计：**
*   **读页数 (4页)**：
    1.  读根节点。
    2.  读左内部节点。
    3.  读目标叶节点 [8, 10]。
    4.  读左兄弟叶节点 [1, 2, 5, 6] (为了借数据)。
*   **写页数 (3页)**：
    1.  写回更新后的左兄弟 [1, 2, 5]。
    2.  写回更新后的当前叶节点 [6, 10]。
    3.  写回更新后的父节点 (关键字8变6)。

**结果树局部变化**：
*   左内部节点关键字变为：[**6**, 18, 32, 40]。
*   对应的前两个叶节点变为：[1\*, 2\*, 5\*] 和 [6\*, 10\*]。

#### (3) 给出在原树中先插入 46*，然后再删除 52* 之后的 B+树

**第一步：插入 46\***
1.  找到叶节点 [41\*, 45\*] (通过父节点指针 >40)。
2.  插入 46\*。叶节点变为 [41\*, 45\*, 46\*]。
3.  数量为3，小于最大值4。**插入完成，无分裂**。

**第二步：删除 52\***
1.  找到叶节点 [52\*, 58\*] (通过根右侧，内部节点 [73, 85] 的 <73 指针)。
2.  删除 52\*。叶节点变为 [58\*]。
3.  **下溢**：数量1 < 最小2。
4.  **查看兄弟** (在同一父节点 [73, 85] 下)：
    *   右兄弟 [73\*, 80\*] 只有2个元素 (最小)。无法借。
    *   **策略**：必须与兄弟**合并 (Merge)**。
5.  **合并操作**：
    *   将 [58\*] 与 [73\*, 80\*] 合并。
    *   新叶节点：[58\*, 73\*, 80\*]。
    *   **删除父节点中的索引**：父节点 [73, 85] 中分隔这两个叶子的关键字是 73。删除 73。
6.  **检查父节点 (内部节点) 下溢**：
    *   父节点原为 [73, 85]。删除 73 后变为 [85]。
    *   现在该节点只有 1 个关键字 (2个子指针)。
    *   内部节点最小关键字数 = $\lfloor 4/2 \rfloor + 1 - 1 = 2$。
    *   **发生内部节点下溢**。
7.  **内部节点重平衡**：
    *   当前节点 (右内部)：[85]。
    *   左兄弟节点 (左内部)：[8, 18, 32, 40]。
    *   左兄弟有4个关键字 (5个子节点)，是满的。**可以借 (旋转)**。
8.  **旋转操作 (Borrow from Left Internal Sibling)**：
    *   我们需要把左内部节点的一部分“过继”给右内部节点。
    *   **移动对象**：左内部节点的最右子节点指针 (指向 [41\*, 45\*, 46\*]) 和相关关键字。
    *   **步骤**：
        1.  **左内部节点**：移除最右边的关键字 40 和最右边的指针。剩余 [8, 18, 32]。
        2.  **根节点**：原分隔关键字是 50。将左边借上来的 **40** 替换根节点的 50。根节点变为 [40]。
        3.  **右内部节点**：接收原根节点的 **50**。变为 [50, 85]。
        4.  **指针调整**：
            *   [41\*, 45\*, 46\*] 变成右内部节点的第一个子节点 (小于50)。
            *   [58\*, 73\*, 80\*] 是第二个子节点 (50到85之间)。
            *   [91\*, 95\*] 是第三个子节点 (>85)。

**最终B+树结构描述：**
*   **Root**: [40]
*   **Left Internal**: [8, 18, 32]
    *   Child 1: [1, 2, 5, 6]
    *   Child 2: [8, 10]
    *   Child 3: [18, 27]
    *   Child 4: [32, 39]
*   **Right Internal**: [50, 85]
    *   Child 1: [41, 45, 46]  <-- 从左边移过来的
    *   Child 2: [58, 73, 80]  <-- 合并后的
    *   Child 3: [91, 95]

#### (4) 给出在原树中，依次删除 32*, 39*, 41*, 45* 和 73* 之后的 B+树

**1. 删除 32\* 和 39\***
*   目标叶节点：[32\*, 39\*]。
*   删除 32\*：剩 [39\*]。下溢。
*   看兄弟：左 [18, 27] (2个)，右 [41, 45] (2个)。无法借，只能合并。
*   与左兄弟合并：[18, 27] + [39] -> [18\*, 27\*, 39\*]。
*   父节点 (左内部) 更新：删除索引 32。
*   左内部节点变为：[8, 18, 40]。 (3个关键字，合法)。
*   删除 39\*：从 [18, 27, 39] 删除 39。剩 [18, 27]。合法。
*   **当前状态**：左内部节点 [8, 18, 40]，其第3个指针指向 [18, 27]，第4个指针指向 [41, 45]。

**2. 删除 41\* 和 45\***
*   目标叶节点：[41\*, 45\*]。
*   删除 41\*：剩 [45\*]。下溢。
*   看兄弟：左兄弟是 [18, 27]。无法借，合并。
*   合并：[18, 27] + [45] -> [18\*, 27\*, 45\*]。
*   父节点 (左内部) 更新：删除索引 40。
*   左内部节点变为：[8, 18]。 (2个关键字，刚好满足最小值)。
*   删除 45\*：从 [18, 27, 45] 删除 45。剩 [18, 27]。合法。
*   **当前状态**：左内部节点 [8, 18]。其子节点依次为 [1..], [8..], [18, 27]。

**3. 删除 73\***
*   目标：右侧子树。右内部节点 [73, 85]。叶节点 [73, 80]。
*   删除 73\*：叶节点剩 [80\*]。下溢。
*   看兄弟：左 [52, 58] (2个)，右 [91, 95] (2个)。无法借，合并。
*   与左兄弟合并：[52, 58] + [80] -> [52\*, 58\*, 80\*]。
*   父节点 (右内部) 更新：删除索引 73。
*   右内部节点变为：[85]。 (1个关键字)。
*   **内部节点下溢**：右内部节点只有1个关键字，少于最小限制2。
*   **内部节点重平衡**：
    *   查看兄弟 (左内部节点)：当前为 [8, 18]。
    *   左兄弟也只有2个关键字 (最小值)。无法借。
    *   **必须合并两个内部节点**。
*   **合并内部节点**：
    *   合并对象：左内部 [8, 18] + 根节点分隔符 [50] + 右内部 [85]。
    *   新节点内容：[8, 18, 50, 85]。
    *   新节点的子节点依次指向：
        1. [1, 2, 5, 6]
        2. [8, 10]
        3. [18, 27] (前面步骤合并剩下的)
        4. [52, 58, 80] (前面步骤合并剩下的)
        5. [91, 95]
*   **根节点塌缩**：
    *   原根节点 [50] 的关键字下移参与合并后，根节点为空。
    *   上述合并后的新节点 [8, 18, 50, 85] 成为**新的根节点**。
    *   树的高度降低一层。

**最终 B+树结构：**
*   **Root**: [8, 18, 50, 85] (单节点，既是根也是叶的父节点)
*   **Leaf Nodes (从左到右)**:
    1.  [1\*, 2\*, 5\*, 6\*]
    2.  [8\*, 10\*]
    3.  [18\*, 27\*]
    4.  [52\*, 58\*, 80\*]
    5.  [91\*, 95\*]

#### **习题 5.3：B+树深度剖析**

考虑B+树索引：内节点可容纳 **4 个键值**和 **5 个指针**；叶节点直接存储数据记录，可容纳 **4 条记录**且相邻叶节点之间用双链连接在一起。

**【知识点扫盲】**
1.  **范围查询 (Range Scan)**：先像查字典一样找到“起点”，然后沿着叶子节点的链表（横向）一直读下去。
2.  **树的高度增加**：只有当**根节点 (Root)** 满了，并且分裂了，树才会长高一层。

**【详细解题过程】**

#### **(1) 范围查询：> 38**
*   **第一步：找起点 (38)**
    *   从根 (Root) 开始。
    *   找中间层节点 (I1, I2...)。
    *   最终定位到包含 38 的叶子节点。看图 5.22，38 在叶子 **L2** `[36*, 38*]` 中。
*   **第二步：横向扫描**
    *   从 L2 开始，顺着链表往右读。
    *   读取 **L2** (38在此)。
    *   读取 **L3** (`42*, 43*`)。
    *   读取 **L4** (`51*, 52*, 56*, 60*`)。
    *   读取 **L5, L6, L7, L8**... 直到最右边。
*   **涉及节点**：
    *   **索引路径**：Root $\rightarrow$ I1 $\rightarrow$ I2 $\rightarrow$ L2。
    *   **数据路径**：L2, L3, L4, L5, L6, L7, L8。

#### **(2) 插入 109\***
*   **定位**：109 比 100 大。去最右边的叶子 **L8** `[98*, 99*, 100*, 105*]`。
*   **冲突**：题目说叶子最多容纳 **4 条**记录。L8 已经有 4 条了。**溢出！**
*   **分裂操作**：
    *   5 条记录 (98, 99, 100, 105, 109) 分成两半。
    *   通常策略：左 2 右 3，或左 3 右 2。
    *   **新 L8**：`[98*, 99*]`。
    *   **新 L9**：`[100*, 105*, 109*]`。
*   **向上更新**：
    *   分裂产生了新节点，需要在父节点（I3）中插入一个新的分界键值（通常是新右节点的最小值 **100**）。
    *   父节点 I3 原本有 `[90, 98]`，现在变成 `[90, 98, 100]`。未满，插入结束。

#### **(3) 删除 81\***
*   **定位**：81 在叶子 **L6** `[81*, 82*]`。
*   **删除**：删掉 81。L6 剩 `[82*]`。
*   **下溢检查**：叶子容量 4。剩 1 个太少（通常要求 $\lceil 4/2 \rceil = 2$）。
*   **借位/合并**：
    *   看右兄弟 **L7**：`[94*, 95*, 96*, 97*]` (4个，满的)。
    *   **借位策略**：从 L7 借一个最小的 (94) 给 L6？
    *   或者看左兄弟（图上没画全，假设不方便借）。
    *   **截图答案策略**：答案展示了 **L6 和 L7 重组**。
    *   将 L6 的 `82` 和 L7 的 `94, 95, 96, 97` 重新分配。
    *   或者：如果 L6 太空，直接和兄弟合并，或者从兄弟匀一个过来。
    *   *答案图示*：L6 变成了 `[82*, 94*]`，L7 变成了 `[95*, 96*, 97*]`。父节点的分界值相应更新（从94变95）。

#### **(4) 插入什么会让树长高？**
*   **原理**：树长高 $\Leftrightarrow$ 根节点分裂。
*   **逆推**：
    *   根节点 (Root) 现在有 4 个键值 `10, 20, 30, 80`。题目说内节点最多容纳 **4 个键值**。
    *   **根已经满了！**
    *   只要再往根节点插入 **任何一个** 新的键值，根就会分裂，树就会长高。
*   **如何往根插入键值？**
    *   需要底层的子节点（I1, I2...）分裂，把中间值顶上来。
    *   **I2** 节点 `[35, 42, 50, 65]` 也满了（4个）。
    *   只要在 I2 下面的叶子（如 L3, L4）里疯狂插入数据，导致 I2 分裂，I2 分裂会往 Root 塞一个键值。
    *   **结论**：在 **[30, 80]** 这个范围（对应 I2）内插入大量数据（如 65, 79 之间的数），导致 I2 溢出，进而导致 Root 溢出。

#### **(5) 推测子树 A、B、C 的内容**
这是一个逻辑推理题。
*   **观察父节点**：Root 的第一个指针指向子树，范围是 **< 10**。但图上 Root 的第一个指针指向了 **I1**。
    *   I1 的键值是 `...` (图上没画全)。
    *   我们看 **I2**。I2 的键值是 `35, 42, 50, 65`。
    *   I2 是 Root 的第 3 个孩子（对应 20 和 30 之间？不对，看连线）。
*   **看连线逻辑**：
    *   Root 的键是 `10, 20, 30, 80`。
    *   **指针 0 (<10)** $\rightarrow$ 指向最左边的子树（包含 A, B, C 的那个节点）。
    *   让我们看那个节点（标号 11？看不清，假设是 I1）。
    *   I1 的父指针来自 Root 的 `<10` 区域。
    *   所以 I1 覆盖的范围是 **负无穷 到 10**。
*   **推测 A, B, C**：
    *   A, B, C 是 I1 的子节点（叶子）。
    *   I1 必须填满才能让树看起来平衡。
    *   I1 的范围是 `<10`。
    *   所以 A, B, C 里面存的数据都是 **小于 10** 的整数。
    *   **形状**：它们应该是叶子节点，包含 1~9 的数据，并且每个节点至少半满（2个数据）。
    *   **答案补充**：
        1.  它们都是树高为 1 的子树（叶子）。
        2.  子树 A 包含的值肯定 $< 键值1$。
        3.  每个中间节点至少含有 3 个键值和 3 个指针（基于 $m=4$ 或 $m=5$ 的填充率推断）。

#### **习题 5.7：可扩展散列**

1.  **桶（Bucket）**：
    *   这就是书架。图右边的方框就是桶。
    *   每个桶有一定的**容量**。从图中 `桶A2` 有4个数据（4, 12, 20, 36）可以看出，**桶的容量是 4**。如果第5个数据来了，桶就爆了，需要分裂。

2.  **哈希值（Hash Value）**：
    *   这是书的索书号。在这个题目中，我们把数字转成**二进制**来看。可扩展散列通常使用二进制的**最后几位（后缀）**来分类。
    *   比如数字 `32`，二进制是 `100000`。如果看最后2位，它是 `00`。

3.  **目录（Directory）**：
    *   图左边的列表（000, 001...）就是目录。它是一个指针数组，指向具体的桶。

4.  **全局深度（Global Depth）**：
    *   **定义**：目录需要看二进制的**后几位**来区分桶。
    *   **图中**：目录有 8 项（$2^3=8$），从 `000` 到 `111`。说明**全局深度 = 3**。也就是说，系统目前根据数字的**最后 3 位**来分配桶。

5.  **局部深度（Local Depth）**：
    *   **定义**：具体的某个桶，实际上是根据**后几位**分进来的。
    *   **例子**：
        *   **桶 A** 的方块上写着 `3`。说明桶 A 里的数据，**后 3 位**都是一样的（看连线，是 `000`）。
        *   **桶 B** 的方块上写着 `2`。说明桶 B 里的数据，只要**后 2 位**一样（是 `01`），就都放这儿。
        *   **关键点**：你看目录左边，`001` 和 `101`（后两位都是 `01`）都指向了桶 B。这就是为什么桶 B 的局部深度只有 2。

6.  **分裂规则（最重要！）**：
    *   当一个桶满了，这就需要分裂。
    *   **情况 1：局部深度 < 全局深度**。
        *   说明目录已经分得够细了，只是这个桶还是共用的。
        *   **操作**：不用翻倍目录。直接把这个桶一分为二，局部深度 +1，调整目录指针。
    *   **情况 2：局部深度 = 全局深度**。
        *   说明目录分得不够细，无法区分更多数据了。
        *   **操作**：**目录翻倍**（全局深度 +1），然后分裂桶，重新分配数据。

#### 题目 (1) (2) (3) ：关于“最后插入项”的判断

*   **问题 (1)**：从图中，我们能否看出哪个是最后插入的项？=
    *   **解析**：哈希（Hash）的本质就是**打乱顺序**。数据在桶内是无序存放的（或者按数值大小排序，但不是按时间排序）。桶 A 里的 `64` 和 `16`，谁先来谁后来，从静态图上完全看不出来。

*   **问题 (2)**：若已知无删除，能否看出哪个是最后插入的项？
    *   **解析**：同上，插入顺序在哈希结构中不被保留。

*   **问题 (3)**：若已知无删除，能否看出哪个是**导致桶分裂**的最后插入项？
    *   **解析**：
        *   我们观察图，**桶 A**（深度3）和 **桶 A2**（深度3）显然是由同一个“老桶”（深度2，对应后缀 `00`）分裂而来的。
        *   **桶 A** 包含：`64` (...000), `16` (...000)。
        *   **桶 A2** 包含：`4` (...100), `12` (...100), `20` (...100), `36` (...100)。此时 A2 已经满了（4个）。
        *   虽然我们知道分裂发生了，但导致分裂的那次插入，可能是 A 里的数据，也可能是 A2 里的数据。

#### 题目 (4)：插入 68*

1.  **分析数据 68**：
    *   68 的二进制：`1000100`。
    *   当前全局深度是 3，看**后 3 位**：`100`。

2.  **查找目录**：
    *   目录 `100` 指向 **桶 A2**。

3.  **检查桶 A2**：
    *   桶 A2 目前有：`4*, 12*, 20*, 36*`。
    *   **容量**：4个。已经**满**了！
    *   **深度检查**：桶 A2 的局部深度是 **3**。当前全局深度也是 **3**。
    *   **结论**：因为 **局部深度 = 全局深度**，且桶满了，所以必须 **目录翻倍**！

4.  **操作步骤**：
    *   **第一步：目录翻倍**。
        *   全局深度变 **4**。
        *   目录项变为 16 个：`0000` 到 `1111`。
    *   **第二步：分裂桶 A2**。
        *   原桶 A2 负责 `100`。现在根据第 4 位（从右往左数）分裂成两个新桶：
            *   负责 `0100` 的桶。
            *   负责 `1100` 的桶。
    *   **第三步：重新分配数据**（看 68 和原 A2 里的数据）。
        *   我们要看数据的**后 4 位**：
        *   `4` (..000100) -> 后4位 `0100`
        *   `20` (..010100) -> 后4位 `0100`
        *   `36` (..100100) -> 后4位 `0100`
        *   `68` (..1000100) -> 后4位 `0100`
        *   `12` (..001100) -> 后4位 `1100`
    *   **第四步：结果**。
        *   **新桶 A2**（局部深度4，对应 `0100`）：存放 `4, 20, 36, 68`。
        *   **新桶 A3**（局部深度4，对应 `1100`）：存放 `12`。
        *   目录指针：`0100` 指向新 A2，`1100` 指向新 A3。其他目录项（如 `0000` 和 `1000`）都指向原来的桶。

#### 题目 (5)：插入 17*、69*

1.  **插入 17\***：
    *   17 二进制：`10001`。后3位：`001`。
    *   目录 `001` 指向 **桶 B**。
    *   桶 B (`1, 5, 21`) 有 3 个数据，没满。
    *   **结果**：直接把 17 放入桶 B。桶 B 变满。

2.  **插入 69\***：
    *   69 二进制：`1000101`。后3位：`101`。
    *   目录 `101` 指向 **桶 B**（注意：`001` 和 `101` 指向同一个桶 B）。
    *   **检查桶 B**：此时里面有 `1, 5, 21, 17`。**满**了！
    *   **深度检查**：桶 B 的局部深度是 **2**。全局深度是 **3**。
    *   **结论**：因为 **局部深度 < 全局深度**，**不需要**翻倍目录，只需要**分裂桶 B**。

3.  **操作步骤**：
    *   **第一步：分裂桶 B**。
        *   桶 B 原本负责后缀 `01`（深度2）。现在升级为深度 3。
        *   分裂成：负责 `001` 的桶 和 负责 `101` 的桶。
    *   **第二步：重新分配数据**（1, 5, 21, 17, 69）。
        *   看**后 3 位**：
        *   `1` (..001) -> `001`
        *   `17` (..010001) -> `001`
        *   `5` (..101) -> `101`
        *   `21` (..10101) -> `101`
        *   `69` (..1000101) -> `101`
    *   **第三步：结果**。
        *   **桶 B**（局部深度3，对应 `001`）：存放 `1, 17`。
        *   **新桶 B2**（局部深度3，对应 `101`）：存放 `5, 21, 69`。
        *   **更新目录**：目录 `001` 指向桶 B，目录 `101` 指向桶 B2。

#### 题目 (6)：删除 21*

1.  **分析数据 21**：
    *   21 二进制：`10101`。
    *   后3位 `101`。
    *   查找目录 `101`，指向 **桶 B**。
2.  **操作**：
    *   在桶 B 中找到 `21*`，直接删除。
    *   桶 B 剩下 `1*, 5*`。
3.  **是否合并？**
    *   一般考试中，除非特别要求“合并桶”，否则删除操作只需把数据拿走，留出空位即可。
    *   如果需要合并，需要检查桶 B 的“伙伴桶”（Buddy Bucket，即只有某一位不同的桶）。但在这里，简单删除即可。

### **习题 5.12：线性散列详解**

> **重要提示**：题目中存在一个明显的**印刷错误或术语混淆**。**本题必须按线性散列 (Linear Hashing) 来解**。
> *   **题干文字**说：“给出基于**可扩展散列 (Extendible Hashing)** 的...结构图”。
> *   **配图 (图 5.24)** 和 **问题 (Next 值)** 却完全是 **线性散列 (Linear Hashing)** 的特征（Next 指针、Level、h1/h0）。
>    *   *可扩展散列*使用的是全局深度/局部深度，没有 Next 指针。
>    *   *线性散列*才使用 Next 指针来控制分裂。

**【当前状态分析 (图 5.24)】**
*   **桶容量**：观察桶 `011` (11) 有 4 个元素 (`31*, 15*, 7*, 3*`) 且看起来满了。假设 **桶容量 = 4**。
*   **当前参数**：`Level = 0`, `N = 4` (当前有4个桶), `Next = 0` (指向桶 00)。
*   **散列函数**：
    *   $h_0$: 取二进制最后 **2** 位。
    *   $h_1$: 取二进制最后 **3** 位（用于分裂时）。
*   **桶内数据现状**：
    *   **桶 00**: `64*` (...00), `44*` (...00)。(已有 2 个，**空 2 个**)
    *   **桶 01**: `9*` (...01), `25*` (...01), `5*` (...01)。(已有 3 个，**空 1 个**)
    *   **桶 10**: `10*` (...10)。(已有 1 个，**空 3 个**)
    *   **桶 11**: `31*`, `15*`, `7*`, `3*`。(已有 4 个，**空 0 个**)
    *   **总空闲位**：$2 + 1 + 3 + 0 = 6$ 个。

#### **【解题过程】**

**(1) 第一次分裂前可插入的最大数据项数和 Next 值**

*   **知识点**：线性散列的分裂通常由“溢出”触发。为了“不发生分裂”，我们需要填满所有现有的空位，但不产生溢出。
*   **分析**：
    *   题目假设“理想均匀分布”，意味着我们可以完美地将新数据填入当前的空槽中。
    *   目前总共有 **6 个空槽**（见上方状态分析）。
    *   我们可以插入 6 个数据项，分别填入桶 00、01 和 10，使它们都达到满载（4个）。
    *   只要不往已经满的桶 11 插入，或者是其他桶满了之后再插入，就不会触发溢出和分裂。
*   **Next 值**：在分裂发生**之前**，`Next` 指针保持不变。
*   **答案**：
    *   **最大数据项数**：**6 个**。
    *   **Next 值**：**0**。

**(2) 插入一个记录引发分裂后的结构图**

*   **场景**：假设插入一个新记录（例如 `hash(x) = ...11`），它进入了桶 11。
*   **触发分裂**：桶 11 已满 $\rightarrow$ 发生溢出 $\rightarrow$ 触发分裂机制。
*   **分裂规则**：线性散列规定，当**任意**桶发生溢出时，分裂 **Next 指向的桶**（当前是 **桶 00**）。
*   **分裂 桶 00**：
    *   **创建新桶**：添加 **桶 100 (Bucket 4)**。
    *   **重分配数据**：使用 $h_1$（看最后 3 位）将原 **桶 00** 的数据重新分配到 **000** 和 **100**。
        *   **64\*** ($64 = \dots 1000000_2$)：最后3位是 **000** $\rightarrow$ 留在 **桶 00**。
        *   **44\*** ($44 = \dots 0101100_2$)：最后3位是 **100** $\rightarrow$ 移动到 **桶 04**。
    *   **更新指针**：`Next` 值加 1，变为 **1**。
*   **溢出处理**：导致分裂的那条新记录（在桶11）会放在桶11的溢出页中（题目未要求画溢出页，重点是桶00的分裂）。

*   **【答案图示描述】**：
    *   `Next` 指针右移，指向 **桶 01**。
    *   **桶 00** (h1: 000) 内容：`64*`。
    *   **桶 01** ~ **桶 11** 内容不变。
    *   新增 **桶 04** (h1: 100) 内容：`44*`。
    *   (注：原桶11会有溢出链，视具体插入值而定)。

**(3) 导致四个桶都发生分裂的最少插入数及 Next 值**

*   **目标**：让 **桶 00, 01, 10, 11** 全部发生一次分裂。这意味着 `Next` 指针要从 0 走到 1, 2, 3，最后回到 0（Level 增加 1）。这被称为完成了一轮（Round）。
*   **分析**：
    *   **分裂条件**：通常假设 **1 次溢出触发 1 次分裂**。
    *   要分裂 4 个桶，我们需要触发 **4 次溢出**。
    *   **理想均匀分布**意味着数据会尽可能均匀地填充空间。为了“最少”插入数，我们假设我们先填满所有空位，然后每次插入都恰好导致溢出。
*   **计算步骤**：
    1.  **填满阶段**：先填满当前所有的 **6 个空位**（参考问题1）。此时所有 4 个桶都满了（每个4项，共16项）。
    2.  **分裂阶段**：
        *   插入第 1 个数 $\rightarrow$ 溢出 $\rightarrow$ Split 桶 00 (`Next`=1)。
        *   插入第 2 个数 $\rightarrow$ 溢出 $\rightarrow$ Split 桶 01 (`Next`=2)。
        *   插入第 3 个数 $\rightarrow$ 溢出 $\rightarrow$ Split 桶 10 (`Next`=3)。
        *   插入第 4 个数 $\rightarrow$ 溢出 $\rightarrow$ Split 桶 11 (`Next` 归零, Level+1)。
    *   **总插入数**：6 (填坑) + 4 (触发分裂) = **10 个**。
*   **Next 值**：当四个桶都分裂完成后，一轮结束，`Next` 指针重置回开头。
*   **答案**：
    *   **最少插入数据项数**：**10 个**。
    *   **Next 值**：**0**。

### **习题 5.13：位图压缩编码计算**

**【知识点扫盲：位图压缩算法】**
我们在课件中使用的压缩算法（通常是 **Run-Length Encoding** 的一种变体）逻辑如下：
1.  **核心思想**：位图中 **0** 很多，我们只记录 **“连续有多少个 0”**（记为 $i$），后面默认跟着一个 **1**。
2.  **编码规则**：将数字 $i$（0的个数）转换为二进制编码。
    *   **特殊情况**：
        *   $i=0$（即 `1` 紧挨着 `1`）：编码为 **00**
        *   $i=1$（即 `01`）：编码为 **01**
    *   **一般情况 ($i > 1$)**：
        1.  算出 $i$ 的二进制表示。假设二进制长度为 $L$。
        2.  **前缀**：写 $L-1$ 个 `1`，再写一个 `0`。
        3.  **后缀**：写 $i$ 的二进制原码。
        *   *举例*：$i=13$ (二进制 `1101`，长度 $L=4$)。3个1加0 $\to$ `1110`。后缀：`1101`。结果：`11101101`。

**【详细解题过程】**
#### **(1) 压缩 `0110000000100000100`**
*   **Step 1：拆分游程（Gap）**
    *   原文：`0` `1` `1` `0000000` `1` `00000` `1` `00`
    *   第1段：1个0，然后是1。 $\to i=1$
    *   第2段：0个0，然后是1。 $\to i=0$
    *   第3段：7个0，然后是1。 $\to i=7$
    *   第4段：5个0，然后是1。 $\to i=5$
    *   第5段：2个0，结束。 $\to i=2$
*   **Step 2：计算编码**
    *   $i=1$: 特殊规则 $\to$ **01**
    *   $i=0$: 特殊规则 $\to$ **00**
    *   $i=7$: 二进制 `111` ($L=3$)。前缀 `110`，后缀 `111` $\to$ **110111**
    *   $i=5$: 二进制 `101` ($L=3$)。前缀 `110`，后缀 `101` $\to$ **110101**
    *   $i=2$: 二进制 `10` ($L=2$)。前缀 `10`，后缀 `10` $\to$ **1010**
*   **结果**：**01001101111101011010**

#### **(2) 压缩 `000100000000010000010000`**
*   **结果**：**10111110100100110101110100**

#### **(3) 解码 `1110100100110110011011`**
*   **解析第1段**：
    *   读取前缀 `1110` $\to$ 3个1 $\to$ 长度 $L=4$。
    *   读取后缀（4位） `1001` $\to$ 数值 9。
    *   含义：**9个0，然后1个1**。
    *   剩余串：`00110110011011`
*   **解析第2段**：
    *   读取 `00` $\to$ 特殊值 $i=0$。
    *   含义：**0个0，然后1个1**。
    *   剩余串：`110110011011`
*   **解析第3段**：
    *   读取前缀 `110` $\to$ 2个1 $\to$ 长度 $L=3$。
    *   读取后缀（3位） `110` $\to$ 数值 6。
    *   含义：**6个0，然后1个1**。
    *   剩余串：`011011`
*   **解析第4段**：
    *   读取 `01` $\to$ 特殊值 $i=1$。
    *   含义：**1个0，然后1个1**。
    *   剩余串：`1011`
*   **解析第5段**：
    *   读取前缀 `10` $\to$ 1个1 $\to$ 长度 $L=2$。
    *   读取后缀（2位） `11` $\to$ 数值 3。
    *   含义：**3个0，然后1个1**（或结束）。
*   **最终位图**：
    `0000000001` `1` `0000001` `01` `000`

### **习题 6.3：外部排序与查询优化综合计算**

**【题目背景】**
*   有一个关系表 `Executives`（高管表）。
*   **数据量**：总共有 **10,000 个页** (M = 10,000)。
*   **内存限制**：可用缓冲页 **B = 10 页**。
*   **查询语句**：
    ```sql
    SELECT DISTINCT E.title, E.ename FROM Executives E
    ```

#### **(1) 初始排序阶段 (Pass 0) 的代价**

计算初始排序阶段（Pass 0）产生的子表（Runs）数目，并计算该阶段的总 I/O 代价。

**Pass 0 (初始归并段生成)**：
    *   **动作**：读进内存 -> 内存排序 -> 写回磁盘。
    *   **能够处理的大小**：每次只能读进 $B$ 页。
    *   **Cost**：读一次全表 + 写一次（变小后的）全表。

**【详细解题过程】**
1.  **读入数据**：
    *   扫描原始关系表 `Executives`。
    *   代价 = **10,000 I/Os**。
2.  **投影与缩减**：
    *   题目答案暗示：只保留 `title` 和 `ename` 后，数据体积变成了原来的 **50%**。
    *   所以需要写回磁盘的数据量 = $10,000 \times 0.5 = \mathbf{5,000 \text{ 页}}$。
3.  **生成子表 (Runs)**：
    *   内存 B=10。
    *   每次处理 10 页。
    *   子表数量 = $5,000 \text{ (新大小)} / 10 = \mathbf{500 \text{ 个子表}}$。
    *   *(注：截图答案写“产生5000个子表”可能是笔误或者指原表分块，但计算逻辑是按 5000 页写的)*。
4.  **计算 Pass 0 总代价**：
    *   **读 (原表)** + **写 (投影表)**
    *   $10,000 + 5,000 = \mathbf{15,000 \text{ I/Os}}$。

#### **(2) 归并阶段 (Merge Passes) 的代价**

为了合并上述子表，计算还需要多少个归并阶段，以及归并阶段的总 I/O 代价。

1.  **N路归并**：你有 $B=10$ 个缓冲页。
    *   **1个页**：用来做输出（Output）。
    *   **9个页**：用来做输入（Input）。
    *   所以，一次只能把 **9** 个小文件合并成 **1** 个大文件。这叫 **9路归并**。
2.  **归并层数计算**：就像打比赛晋级一样。500 个队伍，9个一组比赛，要比几轮才能决出总冠军（合并成1个文件）？
    *   公式：$\lceil \log_{B-1}(\text{子表数}) \rceil$。
3.  **归并代价**：每一轮归并，都要把所有数据（现在的 5000 页）**读一遍、写一遍**。
    *   单轮代价 = $2 \times \text{数据量}$。

**【详细解题过程】**
1.  **计算需要几轮**：
    *   子表数：500 个（来自上一问）。
    *   归并能力：9 路。
    *   第 1 轮后剩：$500 / 9 \approx 56$ 个。
    *   第 2 轮后剩：$56 / 9 \approx 7$ 个。
    *   第 3 轮后剩：$7 / 9 \approx 1$ 个（完成）。
    *   **结论**：需要 **3 个归并阶段**。
2.  **计算归并总代价**：
    *   每一轮都要处理 5,000 页数据。
    *   每轮 I/O = 读 5,000 + 写 5,000 = 10,000。
    *   总轮数 = 3。
    *   **总代价** = $3 \times 10,000 = \mathbf{30,000 \text{ I/Os}}$。

*   **当前总排序代价**（Pass 0 + Merge）= $15,000 + 30,000 = \mathbf{45,000 \text{ I/Os}}$。

### **(3) 利用索引进行查询的详细分析**

*   **查询语句**：`SELECT DISTINCT E.title, E.ename FROM Executives E`
*   **数据背景**：
    *   总记录数：**100,000 条**。
    *   数据页数（堆文件）：**10,000 页**（每页存 10 条记录）。
    *   索引假设：假设在 `title` 属性上建立 B+ 树索引。
    *   索引容量假设：每页可存储 **40 个**索引项（$10 \times 4$）。
*   **问题**：
    1.  如果是**聚簇 (Clustered) B+树索引**，代价是多少？
    2.  如果是**非聚簇 (Unclustered) B+树索引**，代价是多少？
    3.  如果是**散列 (Hash) 索引**，情况如何？

#### **1. 基础参数计算（标准答案的第一步）**

*   **索引叶节点数量计算**：
    *   总记录数：100,000 条。
    *   每个索引页能存：40 个索引项（题干假设数据密度是数据页的4倍）。
    *   索引叶节点页数 = $100,000 \div 40 = \mathbf{2,500 \text{ 页}}$。
    *   **结论**：光扫描索引本身（不拿数据），至少需要 **2,500 I/O**。

#### **2. 情况 A：利用 title 上的【聚簇】B+树索引**

**【详细解析】**
*   **什么是聚簇索引？**
    *   聚簇索引的叶子节点**就是数据文件本身**。数据是按照 `title` 排序存储的。
*   **为什么代价是 12,500 而不是 10,000？**
    *   **堆文件 (Heap File)**：数据是紧凑堆放的，填满一页再填下一页。总共 **10,000 页**。
    *   **B+树文件**：为了维持树的结构（方便分裂和合并），B+树的节点通常不会填满（通常有填充率，比如 67%~80%），而且还有非叶子节点的开销。
    *   **标准答案的假设**：由于 B+ 树的结构开销和填充率问题，存储同样的数据，聚簇索引文件比堆文件要大。这里答案**估算**为 **12,500 页**（比堆文件多 25%）。
*   **执行过程**：
    *   扫描整个聚簇索引的叶子层（即读取所有数据）。
    *   **代价**：**12,500 I/O**。
*   **这一步的意义**：
    *   虽然读 12,500 页比直接扫堆文件（10,000 页）慢。
    *   **但是！** 读出来的数据是**按 title 排好序的**。
    *   对于 `DISTINCT` 操作，如果是已排序的数据，去重只需要扫描一遍（把相邻重复的扔掉），**不需要再进行昂贵的外部排序**（之前算过要 45,000 I/O）。
    *   **结论**：**12,500 (索引扫描) < 45,000 (全排序)**。这是一个很好的方案。

#### **3. 情况 B：利用 title 上的【非聚簇】B+树索引**

**【详细解析】**
*   **什么是非聚簇索引？**
    *   索引页（2,500页）和数据页（10,000页）是分开的。
    *   索引里只有 `title` 和指针。查询还需要 `ename`，所以必须**回表**去查数据页。
*   **执行过程**：
    1.  **扫描索引**：读取所有索引叶子页。
        *   代价 = **2,500 I/O**。
    2.  **回表读取数据**：对于索引中的**每一条**记录，都要根据指针去读数据页拿 `ename`。
        *   总记录数 = 100,000 条。
        *   因为是非聚簇的，数据在物理上是乱序的。索引里相邻的记录，可能在磁盘上相隔十万八千里。
        *   **最坏情况**：每读一条记录，就是一次**随机 I/O**。
        *   代价 = **100,000 I/O**。
*   **总代价**：
    *   $2,500 \text{ (索引)} + 100,000 \text{ (数据)} = \mathbf{102,500 \text{ I/O}}$。
*   **关于答案中提到的 $100,000 \times 10$**：
    *   这是一个极端的“最坏情况”估算。如果内存非常小（比如只有几页），而每次读取一个数据页只能利用其中的 1 条元组（一页有10条），且读完就被置换出去。那么为了读 100,000 条记录，可能导致同一个页被反复从磁盘读取多次。
    *   不管是否乘以10，**102,500** 已经远远大于直接排序的 **45,000**。
*   **结论**：**非常差**。这种情况下优化器绝对不会走非聚簇索引，宁愿全表扫描。

#### **4. 情况 C：利用散列 (Hash) 索引**

**【详细解析】**
*   **聚簇散列索引**：数据直接存在哈希桶里。
*   **特点**：
    *   哈希索引本身**不提供排序**。读出来的数据是乱序的。
    *   **但是**，哈希通过计算将相同的 `title` 放在同一个桶（Bucket）里。
*   **为什么“代价很好”？**
    *   虽然哈希不排序，但对于 `DISTINCT`（去重）操作，我们不需要全排序，只需要把“相同的放在一起”就行。
    *   哈希天然完成了“分组”。去重时，只需要在每个桶内部去重即可（基于哈希的去重算法）。
    *   这避免了昂贵的 $O(N \log N)$ 排序，只需要 $O(N)$ 的线性扫描。
*   **结论**：如果结构是聚簇的（不需要回表），其代价接近于全表扫描（约 10,000 ~ 12,500 I/O），且省去了排序步骤，是处理 `DISTINCT` 的优秀方案。

#### **(4) 利用主键特性的代价 (优化方案二)**

假设查询是 `SELECT DISTINCT E.title, E.ename FROM Executives E`。
如果 **ename** 是关系的主码（Primary Key），并且在 **ename** 上建有 **聚集 B+ 树索引**。
(a) 试估算该查询的执行代价，并与之前的排序归并代价进行比较。
(b) 如果该索引是**非聚集**的，代价又是多少？

**【知识点扫盲】**
1.  **主键的唯一性 (Primary Key Uniqueness)**：主键是不重复的。如果查询结果里包含了主键（这里是 `ename`），那么每一行结果天生就是唯一的！
    *   例子：(CEO, 张三), (CFO, 李四), (CEO, 王五)。因为名字不同，整行肯定不同。
2.  **DISTINCT 优化**：既然结果天生唯一，**就不需要去重了**！也就**不需要排序了**！
    *   我们只需要把表从头到尾读一遍（扫描），直接输出就行。
3.  **聚集索引 (Clustered Index)**：数据就在叶子节点里。扫描聚集索引 = 扫描数据文件。
4.  **非聚集索引 (Unclustered Index)**：索引和数据分开。如果通过非聚集索引去拿数据，每次都要跳来跳去（随机I/O），非常慢。

**【详细解题过程】**
**情况 A：ename 上有 聚集索引**
1.  **逻辑判断**：
    *   因为 `ename` 是主键，查询包含 `ename`。
    *   $\therefore$ 不需要做 `DISTINCT` 去重排序。
    *   $\therefore$ 只需要**全表扫描**。
2.  **计算代价**：
    *   扫描聚集索引 = 扫描整个数据文件。
    *   数据文件大小 = 10,000 页。
    *   考虑到 B+ 树会有一些内部节点开销或填充率（Fill Factor），通常会比纯堆文件稍微大一点点。
    *   **截图答案取值**：**12,500 I/Os**（这是对 B+ 树存储开销的估算，核心就是读一遍全表）。
3.  **对比**：
    *   排序归并：45,000。
    *   利用主键优化：12,500。
    *   **结论**：省去了昂贵的排序和写回临时文件的过程，性能大幅提升。

**情况 B：ename 上有 非聚集索引**
1.  **逻辑判断**：
    *   依然不需要排序。
    *   但是，数据是乱序存放的，索引指哪儿，磁头就要飞哪儿。
2.  **计算代价**：
    *   **读索引**：假设索引有 2,500 页。
    *   **回表读数据**：对于索引里的**每一条**记录，都要去读数据页拿 `title`。
    *   总记录数：100,000 条。
    *   最坏情况：读 100,000 次数据页（全是随机 I/O）。
    *   **总代价** = 2,500 (索引) + 100,000 (数据) = **102,500 I/Os**。
3.  **结论**：
    *   非聚集索引扫描（102,500）比直接排序（45,000）还要慢！
    *   **教训**：当需要读取大量数据（全表）时，千万别走非聚集索引，直接扫表（File Scan）才是最快的。

#### **习题 6.4：连接算法**：考虑连接 $R \bowtie_{R.a=S.b} S$。

#### 1. 题目参数梳理

*   **关系 R（大表）：**
    *   元组数 $T(R) = 10,000$
    *   每页元组数 = 10
    *   **页数 $M$** = $10,000 / 10 = \mathbf{1,000}$ 页
*   **关系 S（小表）：**
    *   元组数 $T(S) = 2,000$
    *   每页元组数 = 10
    *   **页数 $N$** = $2,000 / 10 = \mathbf{200}$ 页
*   **缓冲区：**
    *   **可用页数 $B$** = 52 页

#### 2. (1) 嵌套循环连接 (Nested Loop Joins)

**基本原则**：在做连接时，通常选择**较小的表作为外表（Outer Table）**，较大的表作为内表（Inner Table）。

#### (a) 简单嵌套循环连接 (Simple Nested Loop Join, SNLJ)
*   **知识点**：
    *   这是最笨的方法。
    *   逻辑：对于外表 S 的**每一个元组**，都把内表 R 完整扫描一遍。
*   **计算**：
    *   读取外表 S：需要读取 $N$ 页。
    *   读取内表 R：外表有 $T(S)$ 个元组，每读一个元组，就要扫描一次 R（$M$页）。
    *   **总代价** = $N + T(S) \times M$
    *   代入数值 = $200 + 2,000 \times 1,000 = \mathbf{2,000,200}$ 次I/O。
*   **最小缓存页数**：**3页**。
    *   1页存外表输入，1页存内表输入，1页存输出结果。

#### (b) 页嵌套循环连接 (Page-oriented Nested Loop Join, PNLJ)
*   **知识点**：
    *   比上面聪明一点，以“页”为单位。
    *   逻辑：对于外表 S 的**每一页**，都把内表 R 完整扫描一遍。
*   **计算**：
    *   读取外表 S：$N$ 页。
    *   读取内表 R：外表有 $N$ 页，每读一页 S，就要扫描一次 R（$M$页）。
    *   **总代价** = $N + N \times M$
    *   代入数值 = $200 + 200 \times 1,000 = \mathbf{200,200}$ 次I/O。
*   **最小缓存页数**：**3页**。（同上，只需能容纳输入输出即可）。

#### (c) 块嵌套循环连接 (Block Nested Loop Join, BNLJ)
*   **知识点**：
    *   这是最常用的优化方法。利用内存缓冲区，一次读入一大块外表。
    *   **块的大小**：我们有 $B=52$ 个缓冲页，我们要留1页给内表输入，1页给结果输出。所以，一次可以读入 **$B-2 = 50$** 页的外表 S。
    *   逻辑：把 S 分成若干个“块”，每处理一个块，扫描一次 R。
*   **计算**：
    1.  **确定块数**：外表 S 共 200 页，每次读 50 页。需要读几批？
        $$ \lceil 200 / 50 \rceil = 4 \text{ 批} $$
    2.  **计算代价**：
        *   读取外表 S：总共 200 页（不管分几批，总归要读进来一次）。
        *   读取内表 R：一共分了 4 批，所以 R 被扫描 4 次。
        *   **总代价** = $N + (\text{批次数}) \times M$
        *   代入数值 = $200 + 4 \times 1,000 = \mathbf{4,200}$ 次I/O。
*   **实现该代价所需的最小缓存**：**52页**。
    *   注意：虽然理论上 BNLJ 只要 3 页缓存就能跑（一次读1页），但那样代价就变回“页嵌套循环”了。题目问的是“实现相应算法（得出4200这个代价）”需要的缓存，也就是为了达到一次读50页S的效果，你需要用满 52 页。

### 3. (2) 排序-归并连接 (Sort-Merge Join)

*   **知识点**：
    *   先将 R 和 S 分别排序，然后进行归并（Merge）操作。
    *   **排序代价**：对于大文件，通常使用两阶段多路归并排序。
        *   阶段1（生成初始归并段 Run）：读一次写一次，代价 $2M$。生成的 Run 大小为 $B$。
        *   阶段2（归并）：如果 Run 的数量小于可用缓冲区，可以一次归并完成。代价 $2M$。
        *   总排序代价通常估算为 $4M$（读写各2次）。
    *   **连接代价**：排序后，只需要扫一遍 R 和 S 就能完成连接，代价 $M+N$。
    *   **优化算法（Combined）**：如果内存足够，最后一次归并排序时不写回磁盘，而是**直接**进行 Join。**总代价公式约为 $3(M+N)$**。

*   **最小缓存页数分析（详解图片中的 25 页是怎么来的）**：
    *   要实现上述的“两阶段”排序并一次性归并完成，必须要满足：**缓冲区能同时容纳所有初始生成的子表（Run）各一页**。
    1. **生成初始子表**：利用 52 个缓冲页，对 R 和 S 进行内部排序。
        *   R 生成的子表数：$1,000 / 50 = 20$ 个子表（每页大小近似50，这是为了安全起见留余量，或者是假设部分内存用于其他开销，理论上是 $1000/52 \approx 20$）。
        *   S 生成的子表数：$200 / 50 = 4$ 个子表。
        *   总共需要归并的子表流数量 = $20 + 4 = 24$ 个。
    2. **归并阶段**：要同时归并这 24 个流，我们需要留下 1 个输出缓冲页。
    *   **所需最小缓存** = $24 + 1 = \mathbf{25}$ 页。

### 4. (3) 散列连接 (Hash Join)

*   **知识点**：
    *   **阶段1（分区 Partitioning）**：利用哈希函数 $h1$ 把 R 和 S 分散到 $k$ 个桶中。目的是让小表 S 的每一个桶都能装入内存。
        *   代价：读 R+S，写 R+S。即 $2(M+N)$。
    *   **阶段2（探测 Probing）**：对于每一对桶 $(R_i, S_i)$，把较小的 $S_i$ 读入内存建立哈希表，然后扫描 $R_i$ 进行匹配。
        *   代价：读 R+S。即 $(M+N)$。
    *   **总代价**：$2(M+N) + (M+N) = \mathbf{3(M+N)}$。

*   **计算**：
    *   **代价** = $3 \times (1,000 + 200) = \mathbf{3,600}$ 次I/O。

*   **最小缓存页数分析**：
    *   Hash Join 能在两遍（Two-pass）内完成的条件是：**小表（S）划分后的每一个分区（Partition）必须能放入内存**。
    *   假设分区时的哈希桶数量为 $k$，那么每个分区的大小约为 $N/k$。
    *   在分区阶段，我们需要 $k$ 个输出缓冲页 + 1 个输入页，所以 $B > k$。
    *   在探测阶段，我们需要内存能装下一个分区（$N/k$）+ 建立哈希表的开销（模糊因子 $f$）+ 输入页。即 $B > f \times (N/k)$。
    *   综合推导，内存 $B$ 大致需要满足 **$B > \sqrt{f \times N}$**。
    *   **解题数值**：
        *   题目设定模糊因子 $f = 1.2$。小表 S 的页数 $N=200$。
        *   正确推导应为：$\sqrt{1.2 \times 200} = \sqrt{240} \approx 15.5$。即需要约 **16 页** 缓存。
    *   **考试时建议写出公式 $B \approx \sqrt{f \times N}$ 并代入实际数值计算。**

#### **习题 7.3：为了查 10% 的数据，该怎么选索引？**

1.  **方案 (a)：非聚集索引 (Unclustered Index)**
    *   **过程**：
        1.  先查目录，找到了所有 'EFO' 的条目（很快）。
        2.  **坑来了**：目录说第一篇在第1页，第二篇在第500页，第三篇在第20页……因为是非聚集的，为了读这 10% 的数据，磁头要在磁盘上疯狂乱跳。
    *   **算账**：读目录代价 + **读数据代价**。读数据最坏情况是每读一行就要跳一次磁盘。代价巨大，甚至可能超过直接从头读到尾。
    *   **结论**：**不好**。标准答案推荐“文件扫描”（直接翻书）。

2.  **方案 (b)：聚集索引 (Clustered Index)**
    *   **过程**：
        1.  查目录，找到 'EFO' 开始的地方（比如第 500 页）。
        2.  **顺着读**：因为正文也是排好序的，接下来的 10% 内容全都连在一起。直接从第 500 页一口气读到第 1500 页就行。
    *   **算账**：读目录（2次 I/O） + 读那连续的 1000 页数据。
    *   **代价**：约 1252 次。
    *   **结论**：**这是最好计划**。比全表扫描（10000次）快得多。

3.  **方案 (c)：组合索引**
    *   **过程**：目录太详细了，只用读目录，不读正文。
    *   **算账**：目录虽然比正文薄，但也有 5000 页（叶子节点）。读 5000 页还是比读 1252 页（方案 b）要慢。

#### **习题 7.4：内存不够大，怎么做排序连接？**

#### **第一阶段：准备工作（把题目翻译成数字）**

数据库计算 I/O（读写次数）的核心单位是**页 (Page)**。

1.  **基础参数**：
    *   **页大小**：1K = 1024 字节。
    *   **表 R**：共 10 页。每个元组 300 字节。
        *   一页能装几个？$1024 \div 300 \approx 3$ 个。
        *   **R 的总行数**：$10 \text{页} \times 3 \text{个} = 30$ 行。
    *   **表 S**：共 100 页。每个元组 500 字节。
        *   一页能装几个？$1024 \div 500 \approx 2$ 个。
        *   **S 的总行数**：$100 \text{页} \times 2 \text{个} = 200$ 行。

2.  **关键动作：投影（瘦身）**
    题目说“删除不用的属性”。这意味着数据处理后会变小（变瘦），占用的页数也会变少。
    *   **R 变瘦后**：只剩属性 A, B。题目给信息 (A+B) 大小为 200 字节。
        *   一页能装几个？$1024 \div 200 \approx 5$ 个。
        *   R 总共 30 行，需要几页？$30 \div 5 = \mathbf{6 \text{ 页}}$。
        *   *（记下来：R 从 10 页瘦身成了 6 页）*
    *   **S 变瘦后**：只剩属性 C, D。
        *   题目说最终结果(A,B,C,D)是 450 字节。已知(A,B)是200字节，所以(C,D)是 250 字节。
        *   一页能装几个？$1024 \div 250 \approx 4$ 个。
        *   S 总共 200 行，需要几页？$200 \div 4 = \mathbf{50 \text{ 页}}$。
        *   *（记下来：S 从 100 页瘦身成了 50 页）*

#### **(1) 估算最后输出结果的大小**

*   **逻辑**：连接操作是把 R 和 S 拼起来。题目说“S 中的每个元组都能在 R 中找到匹配”，且 S 有 200 个元组。所以结果也是 200 个元组。
*   **计算**：
    *   结果总行数：200 行。
    *   每行大小：450 字节。
    *   总大小：$200 \times 450 = 90,000 \text{ 字节}$。
    *   换算成页：$90,000 \div 1024 \approx \mathbf{90 \text{ 页}}$（约数）。
*   **答案**：90,000 字节，约 100 页。

#### **(2) 计算三种方案的 I/O 代价**

**方案 ①：“先投影连接” (先瘦身，再连接)**
策略：先读写、排序去重，然后再把瘦身后的它们连起来。

*   **情况 A：内存 B=3 (只有 3 个缓存页)**
    1.  **处理 S (100页瘦身到50页)**：
        *   需要对 S 进行排序去重。内存太小，要分很多趟。
        *   公式：$2 \times 100 \text{页} \times \lceil \log_2(100) \rceil \approx 2 \times 100 \times 7 = \mathbf{1400}$。
    2.  **处理 R (10页瘦身到6页)**：
        *   对 R 排序。因为 R 很小，代价约 **120**。
    3.  **连接 (Join)**：
        *   现在手里是瘦身后的 R(6页) 和 S(50页)。
        *   算法（块嵌套循环）：读 1 遍 R，R 的每一页都要去扫 1 遍 S。
        *   $6 + 6 \times 50 = \mathbf{306}$。
    4.  **总代价**：$1400 + 120 + 306 = \mathbf{1826}$。

*   **情况 B：内存 B=11 (有 11 个缓存页)**
    1.  **处理 S**：
        *   内存大了，归并趟数变少（7趟变2趟）。
        *   代价：$2 \times 100 \times 2 = \mathbf{400}$。
    2.  **处理 R**：
        *   内存 11 页能一次装下 10 页的 R。直接读写一次搞定。
        *   代价：$10(\text{读}) + 10(\text{写}) + \text{其他} \approx \mathbf{30}$。
    3.  **连接**：
        *   依然是瘦身后的表连接：**306**。
    4.  **总代价**：$400 + 30 + 306 = \mathbf{736}$。

**方案 ②：“先连接后投影” (先干活，再瘦身)**
策略：先连接，生成一个巨大的中间文件，写到磁盘上，然后再读回来瘦身。

*   **连接阶段 (通用)**：
    *   用原始的 R(10页) 和 S(100页) 连接。
    *   代价：$10 + 10 \times 100 = \mathbf{1010}$。
    *   **产出**：生成了一个巨大的中间结果。答案估算约为 **200 页**（因为没瘦身，且可能分布松散）。

*   **瘦身阶段 (B=3)**：
    *   要对这 200 页中间结果进行排序、去重。
    *   代价：$200 (\text{读入}) + 2 \times 6 (\text{趟数}) \times 100 (\text{每次处理量}) = \mathbf{1400}$。
    *   *(注：这里答案的计算是个近似值，核心意思是排序200页的代价很高)*

*   **总代价 (B=3)**：
    *   $1010 (\text{连接}) + 1400 (\text{瘦身}) = \mathbf{2410}$。
    *   **评价**：这是最慢的方案。

**方案 ③：“流水线” (Pipeline)**
策略：一边连接，一边把结果直接传给下一步处理，**中间不落地**（不写磁盘）。

*   **计算**：
    *   只计算连接的代价，后续的投影在内存中瞬间完成，不需要额外的磁盘 I/O。
    *   使用原始表连接：$10 + 10 \times 100 = \mathbf{1010}$。
*   **总代价**：**1010**。
*   **评价**：比方案 ① 略好（在内存小的时候），比方案 ② 强得多。

#### **(3) 假定基于块的嵌套循环连接可用**

*   **解释**：我们在第(2)问中计算连接代价时，已经使用了基于块的公式：
    *   **瘦身后的连接**：$Cost = 6 + 6 \times 50 = 306$。
    *   **原始表的连接**：$Cost = 10 + 10 \times 100 = 1010$。
*   **结论**：如果按照此假设重新计算，结果与第(2)问中的各个步骤数值一致。

#### **习题 7.5 (2)：三个表怎么拼最快？**

#### **1. 题目背景与数据侦查**
我们需要连接三个表：
*   **Emp (员工表)**：20,000 条数据。
*   **Dept (部门表)**：5,000 条数据。
*   **Proj (项目表)**：1,000 条数据。

**查询 SQL**：
```sql
SELECT ...
FROM Emp E, Dept D, Proj P
WHERE E.eid = D.did            -- 连接条件 1
  AND D.projid = P.projid      -- 连接条件 2
  AND E.sal = 50,000           -- 过滤条件 A
  AND D.budget > 20,000        -- 过滤条件 B
```

**关键情报**：
1.  **`E.sal = 50,000`**：这是一个**等值查询**。通常工资正好是 50,000 的人很少（假设选择率很低，比如只有 1% 或几条）。这是一个**极好的过滤入口**。
2.  **`D.budget > 20,000`**：这是一个**范围查询**。题目假设 budget 在 0~100,000 均匀分布，大于 20,000 意味着 **80% 的部门都符合**。这过滤力度太弱了，不适合作为第一步。
3.  **索引情况**：解答中假设 `E.sal` 上有**聚集索引**（Clustered Index），`D.did` 上有索引（通常主键/外键都有索引）。

#### **2. 解题步骤：如何构建最佳计划？**

**第一步：谁先上场？（选择驱动表）**

*   **选手 A (Emp)**：有 `sal = 50,000` 的条件。利用聚集索引，可以直接跳到这几条数据，读取量极小（可能就几页 I/O）。
*   **选手 B (Dept)**：有 `budget > 20,000` 的条件。因为符合条件的数据占 80%，如果用索引查，需要读 80% 的数据，基本等于全表扫描。
*   **选手 C (Proj)**：没有任何过滤条件。全表扫描。

**结论**：**选 Emp 先上场**。因为它的过滤条件最狠，能把数据量瞬间降到最低。

**第二步：接下来连谁？（Emp ⋈ ？）**

现在手里攥着那几个“工资5万的员工”，我们要找他们所属的部门。
*   **动作**：拿着员工的 `did`，去 **Dept 表** 里找对应的部门。
*   **方法**：
    *   **索引嵌套循环连接 (Index Nested Loop Join)**。
    *   不需要扫描整个 Dept 表。
    *   直接利用 Dept 表上的 `did` 索引，**精确查找**那几个特定的部门。
*   **顺手牵羊**：查到部门记录后，顺便看一眼 `budget` 是不是大于 20,000。如果是，保留；如果不是，扔掉。

**结论**：第二步连 **Dept**。

**第三步：最后连谁？（... ⋈ Proj）**

现在手里剩下的是“工资5万且部门有钱的员工+部门信息”。我们需要找对应的项目。
*   **动作**：拿着上一步结果中的 `projid`，去 **Proj 表** 里找项目信息。
*   **方法**：
    *   依然是 **索引嵌套循环连接**。
    *   利用 Proj 表上的主键索引 `projid`，精确查找。

#### **3. 为什么这是最佳方案？（代价估算逻辑）**

标准答案给出的方案逻辑如下：

1.  **利用 E.sal 上的聚集索引**：
    *   假设只有很少的员工工资是 50,000。
    *   **代价**：读取索引树高度（2-3次 I/O） + 极少的几页数据。**非常快**。

2.  **流水线 (Pipelining) 连接 Dept**：
    *   不需要把第一步的结果写回磁盘。
    *   每读到一个合规员工，立刻拿着他的 `did` 去查 Dept 索引。
    *   **代价**：因为员工很少，所以查 Dept 索引的次数也很少（随机读几次）。

3.  **流水线连接 Proj**：
    *   同理，每拼好一个 (Emp+Dept)，立刻去查 Proj 索引。
    *   **代价**：次数依然很少。

**总结最优计划 (Text description)**：使用 `E.sal` 上的聚集索引读取 Emp 元组（作为外表/驱动表）；对于每一个 Emp 元组，利用 `D.did` 上的索引去探测 Dept 表（作为内表），并检查预算条件；最后将结果流式传递，利用 `P.projid` 上的索引去探测 Proj 表。

#### **习题 8.2：画圈圈找冲突**

**题目：**
考虑下面的（不完全）调度 S：
$$S: R_1(X), R_1(Y), W_1(X), R_2(Y), W_3(Y), W_1(X), R_2(Y)$$
(1) 假定三个事务最终都正常提交，请画出它们的优先图。S 是否为可串行化调度？如是，请进一步给出与它等价的串行调度。

**【标准解答】**

**(1) 优先图与可串行化分析**

*   **优先图（Precedence Graph）**：节点代表事务，有向边代表冲突依赖关系。
    *   **$T_2 \to T_3$**：因为 S 中 $R_2(Y)$ 在 $W_3(Y)$ 之前（读-写冲突）。
    *   **$T_3 \to T_2$**：因为 S 中 $W_3(Y)$ 在第二个 $R_2(Y)$ 之前（写-读冲突）。
    *   **$T_1 \to T_3$**：因为 S 中 $R_1(Y)$ 在 $W_3(Y)$ 之前。
    *   T2 与 T3 之间存在双向箭头（环路）。T1 指向 T2 和 T3。

*   **是否为可串行化调度？**
    因为其优先图有环（$T_2 \to T_3$ 和 $T_3 \to T_2$），所以，调度 S **不能肯定** 是可串行化调度。
    实际上，因 $R_2(Y)$ 与 $W_3(Y)$ 不可交换，它也 **不是一个冲突可串行化调度**，但是一个 **(视)可串行化调度**。

*   **等价的串行调度**
    其等价的串行调度顺序为（$T_1 \to T_2 \to T_3$）：
    $$R_1(X), R_1(Y), W_1(X), W_1(X), R_2(Y), R_2(Y), W_3(Y)$$

### **解析补充（帮助理解标准答案）**

1.  **为什么不是冲突可串行化？**
    *   看图中 $T_2$ 和 $T_3$ 的关系。
    *   $T_2$ 先读了 Y，这要求 $T_2$ 在 $T_3$（写Y）之前。
    *   $T_3$ 写了 Y 之后，$T_2$ 又读了一次 Y，这要求 $T_3$ 在 $T_2$ 之前。
    *   既要“先”又要“后”，构成了死循环（环路）。凡是有环的，就**不是**冲突可串行化。

2.  **为什么又是“视”可串行化？**
    *   尽管 $T_2$ 和 $T_3$ 在“过程”上打架了，但如果我们看“结果”：
        *   $T_3$ 是**盲写**（它写 Y 之前没有读 Y，不依赖旧数据）。
        *   $T_2$ 是只读事务，不修改数据。
        *   如果我们强制按 $T_1 \to T_2 \to T_3$ 执行，数据库最终留下的 X 是 $T_1$ 写的，Y 是 $T_3$ 写的，这与原调度 S 的**最终状态一致**。

3.  **等价串行调度怎么写出来的？**
    *   就是把三个事务的操作分开，按 $T_1$ 全部做完 $\to$ $T_2$ 全部做完 $\to$ $T_3$ 全部做完 的顺序排列即可。

#### **习题 8.4：如果不加锁会怎样？**

给了两个操作序列 S1 和 S2。问：用不同的规则（2PL、死锁检测、时间戳）去管它们，会发生什么？

**1. 死锁检测 (Strict 2PL)**
*   **S1 序列**：
    *   T1 拿了 X 的锁。
    *   T2 想拿 X 的锁 -> 被 T1 挡住 -> **T2 等待**。
    *   T3 拿了 Y 的锁。
    *   T1 想拿 Y 的锁 -> 被 T3 挡住 -> **T1 等待**。
    *   现在 T1 等 T3，T2 等 T1。如果 T3 再想要 X（被 T1/T2 拿着），就会形成死循环（死锁）。

**2. 保守 2PL (Conservative 2PL)**
*   **规则**：干活前先把所有工具（锁）一次性申请好。如果有一个申请不到，就一个都不拿，回家睡觉待会再来。
*   **结果**：**永不死锁**。但是效率低，因为很难凑齐所有锁。

**3. 基于确认 (Validation)**
*   **规则**：先读写（在私有空间），提交前检查“有没有人插队”。
*   **结果**：T1 是老事务，T2 是新事务。T2 提交时发现和还没写完的老前辈 T1 冲突了。T2 只能**自杀 (Abort)** 重来。

**4. 多版本时间戳**
*   **规则**：按出生日期（时间戳 TS）排辈分。
*   **S1 情况**：
    *   T1 (TS=1) 读了 X。X 上贴标签 `RTS=1`。
    *   T2 (TS=2) 写 X。因为 2 > 1 (T2 比标签新)，允许写。X 标签更新。
    *   T1 后来想写 Y。如果 Y 已经被更年轻的 T3 (TS=3) 读过了，那 T1 就太老了，不能覆盖年轻人的数据。T1 **自杀**。

#### **习题 9.3：标准恢复流程（分析 -> 重做 -> 撤销）**

**场景**：对着图 9.8 (a)，系统在写完 LSN 70 后突然断电崩了。现在重启。
| LSN | 题9.3 | 题9.4 |
| :---: | :--- | :--- |
| **00** | begin_checkpoint | update: T1 writes P2 |
| **10** | end_checkpoint | update: T1 writes P1 |
| **20** | update: T1 writes P5 | update: T2 writes P5 |
| **30** | update: T2 writes P3 | update: T3 writes P3 |
| **40** | T2 commit | T3 commit |
| **50** | T2 end | update: T2 writes P5 |
| **60** | update: T3 writes P3 |
| **70** | T1 abort | T2 abort |
| **状态** | **CRASH, RESTART** | — |

#### **前置核心概念**

1.  **LSN (Log Sequence Number)**：日志的身份证号，单调递增（10, 20, 30...）。
2.  **事务表 (Transaction Table, TT)**：记录“谁还没干完活”。
    *   格式：`{事务ID, 最后一次操作的LSN, 状态}`
3.  **脏页表 (Dirty Page Table, DPT)**：记录“哪一页内存被改脏了，但还没写回硬盘”。
    *   格式：`{页号, recLSN}`
    *   **recLSN (Recovery LSN)**：这一页**第一次**变脏的那条日志号。（非常重要：如果这一页后来又被改了100次，recLSN 依然是第一次那个号。因为它标记了“从哪儿开始烂的”）。

#### **（1）第一阶段：分析 (Analysis)**：搞清楚断电那一刻，谁活着（输家），哪些页脏了。

**动作回放**：
1.  **起点**：找到最近的存档点 `begin_checkpoint` (LSN 00)。此时假设两张表是空的。
2.  **LSN 10 (End Checkpoint)**：没啥用，继续。
3.  **LSN 20 (T1 写 P5)**：
    *   **事务表**：发现新面孔 T1。记下 `{T1, lastLSN:20, Active}`。
    *   **脏页表**：P5 被改了。P5 以前不在表里，所以记下 `{P5, recLSN:20}`。
4.  **LSN 30 (T2 写 P3)**：
    *   **事务表**：发现新面孔 T2。记下 `{T2, lastLSN:30, Active}`。
    *   **脏页表**：P3 被改了。记下 `{P3, recLSN:30}`。
5.  **LSN 40 (T2 Commit)**：
    *   **事务表**：T2 提交了！它是好人。把它的状态改成 `Committing`（或者直接准备踢出去）。
6.  **LSN 50 (T2 End)**：
    *   **事务表**：T2 彻底结束。**从事务表中删除 T2**。
7.  **LSN 60 (T3 写 P3)**：
    *   **事务表**：发现新面孔 T3。记下 `{T3, lastLSN:60, Active}`。
    *   **脏页表**：P3 又被改了。**关键点来了！** 查表发现 P3 已经在里面了（recLSN=30）。**不动它！** 我们只记它第一次变脏的时间。
8.  **LSN 70 (T1 Abort)**：
    *   **事务表**：T1 还在，但状态变了。更新 T1 的最后位置 `{T1, lastLSN:70, Undoing}`。

**分析阶段大结局**：
*   **输家 (Losers)**：T1, T3。（只有它俩还在事务表里）。
*   **脏页**：P5 (recLSN=20), P3 (recLSN=30)。

#### **（2）第二阶段：重做**：先把所有发生过的修改都在硬盘上重演一遍。

**动作回放**：
1.  **从哪开始？** 看脏页表。P5是20，P3是30。最小的是 **20**。所以从 LSN 20 开始重放。
2.  **LSN 20 (T1 写 P5)**：重写 P5。
3.  **LSN 30 (T2 写 P3)**：重写 P3。
4.  **LSN 40, 50**：非数据修改，跳过。
5.  **LSN 60 (T3 写 P3)**：重写 P3。（注意：即使 T3 后来也没提交，这里也要重做，保证内存和断电前一致）。
6.  **LSN 70**：跳过。

**Redo 阶段大结局**：数据库现在的状态 = 断电前那一毫秒的状态。

#### **（3）第三阶段：撤销**：把输家 (T1, T3) 做过的全部回滚。

**动作回放**：
1.  **从哪开始？** 从日志最末尾 (LSN 70) 倒着往回找。
2.  **LSN 70 (T1 Abort)**：T1 说它要回滚。
3.  **LSN 60 (T3 写 P3)**：
    *   这是 T3 干的。T3 是输家。必须撤销！
    *   **动作**：把 P3 的值改回旧值。
    *   **写日志**：写一条 **CLR (补偿日志记录)**，记下“我撤销了 LSN 60”。
4.  **LSN 50, 40**：是 T2 的。T2 已经赢了（Commit），不用管。
5.  **LSN 30 (T2 写 P3)**：T2 的，不用管。
6.  **LSN 20 (T1 写 P5)**：
    *   这是 T1 干的。T1 是输家。撤销！
    *   **动作**：把 P5 改回旧值。
    *   **写日志**：写一条 CLR，记下“我撤销了 LSN 20”。

**Undo 阶段大结局**：T1 和 T3 的痕迹被抹除，数据库干净了。

#### **习题 9.4：Undo 的细节（链表指针）与 CLR**

#### **(4) 在图中增加 prevLSN 和 undonextLSN 标示**

*   **prevLSN (前驱指针)**：
    *   **含义**：同一个事务的“上一条日志”在哪里？
    *   **怎么填**：我们盯着图 9.8(b) 的 `transID` 列看。
    *   **T2 的轨迹**：
        *   LSN 20 (T2 开始写): 第一条，没前驱，`prevLSN = Null` (或 0)。
        *   LSN 50 (T2 写 P5): 上一条是 20。所以 **填 20**。
        *   LSN 60 (T2 写 P3): 上一条是 50。所以 **填 50**。
        *   LSN 70 (T2 Abort): 上一条是 60。所以 **填 60**。
    *   **T1 的轨迹**：
        *   LSN 10: 第一条，`prevLSN = Null`。
        *   (后面没 T1 了)
    *   **T3 的轨迹**：
        *   LSN 30: 第一条，`prevLSN = Null`。
        *   LSN 40 (Commit): 上一条是 30。**填 30**。

*   **undonextLSN (撤销指针)**：
    *   **含义**：**只对 CLR (补偿记录) 有效**。普通记录这里是空的。
    *   **怎么填**：因为图 9.8(b) 展示的是“崩溃前/中止时”的原始日志，里面**还没有开始做撤销操作**，没有 CLR 记录。所以这一列全都是 **— (空)**。
    *   *注*：只有当你开始写 LSN 80, 90... 这些撤销日志时，才需要填这一列（如我上一条回复中 9.4(6) 的部分）。
    
| LSN | prevLSN | undonextLSN<br>(与CLR对应的ULR) |
| :---: | :---: | :---: |
| **00** | — | — |
| **10** | 00 | 00 |
| **20** | — | — |
| **30** | — | — |
| **40** | 30 | (非update记录) |
| **50** | 20 | 20 |
| **60** | 50 | 50 |
| **70** | 60 | (非update记录) |

#### **(5) 描述回滚事务 T2 后执行的动作**： undo 到底把硬盘/内存里的数据变成了啥样。
把 T2 做过的修改全部抹掉，恢复成 T2 没来之前的样子。T2 改了三次：LSN 60 (改P3), LSN 50 (改P5), LSN 20 (改P5)。

*   **动作拆解**：
    1.  **处理 LSN 60**：T2 把 P3 改成了新值。我们要找到 P3 的**旧值**（日志里存了 Old Value）。把内存里的 P3 覆盖回这个旧值。
    2.  **处理 LSN 50**：T2 把 P5 改成了新值。找到 LSN 50 里记录的 P5 旧值，覆盖回去。
    3.  **处理 LSN 20**：T2 第一次改 P5。找到 LSN 20 里记录的 P5 旧值，覆盖回去。

    **结论**：就是拿着日志里的“旧值 (Before Image)”，把数据页刷回老样子。

#### **（6）T2 回滚的过程**：T2 决定回滚（LSN 70 是 T2 Abort）。顺着 T2 的足迹往回走。

1.  **当前状态**：T2 刚写了 LSN 70。
2.  **找上一步**：T2 的上一条日志是 **LSN 60** (update P3)。
3.  **第一步撤销**：
    *   撤销 LSN 60 的修改。
    *   写一条新日志 **LSN 80 (CLR)**。
    *   **关键填空**：
        *   `prevLSN`: 指向 T2 的上一条 (LSN 70)。
        *   `undonextLSN`: **这里填 50**。为什么？因为 LSN 60 这一步我们已经撤销完了，T2 在 60 之前的上一步是 50。所以下次如果出事，直接去搞 50。
4.  **找上一步**：现在处理 LSN 50 (update P5)。
5.  **第二步撤销**：
    *   撤销 LSN 50。
    *   写一条新日志 **LSN 90 (CLR)**。
    *   **关键填空**：
        *   `prevLSN`: 指向刚写的 LSN 80。
        *   `undonextLSN`: **这里填 20**。为什么？因为 LSN 50 的 `prevLSN` 是 20。撤销完 50，下一步该去撤销 20。
6.  **找上一步**：现在处理 LSN 20 (T2 write P5)。
7.  **第三步撤销**：
    *   撤销 LSN 20。
    *   写一条新日志 **LSN 100 (CLR)**。
    *   **关键填空**：
        *   `undonextLSN`: **Null**。因为 LSN 20 是 T2 的第一条记录，前面没了。
8.  **结束**：写 LSN 110 T2 End。

| LSN | prevLSN | transID | Type | pageID | undonextLSN |
| :---: | :---: | :---: | :---: | :---: | :---: |
| **80** | 70 | T2 | CLR | P3 | 50 |
| **90** | 80 | T2 | CLR | P5 | 20 |
| **100** | 90 | T2 | CLR | P5 | — |
| **110** | 100 | T2 | END | — | — |

#### **习题 9.5** 考虑图 9.9 (a) 的日志片段。另外，在恢复期间当系统写两条日志记录到稳定存储后，再次发生崩溃。之后，在写另外两条日志记录到稳定存储后，又再次发生崩溃。**

**核心概念解释**：
1.  **prevLSN** 是用来找“**自己人**”的（同一个事务的上一步）。
2.  **undonextLSN** 是用来**防止死循环**的（记录还没回滚的最早那一步）。
3.  **回滚动作** 就是用日志里的旧值去**覆盖**现在的值。
4.  **2n 条日志** 是因为每个操作最多只会被“报复”（撤销）一次，**好马不吃回头草**。
5.  **Checkpoint 之间有日志** 是因为数据库不想停机，采用了**边跑边拍照**的技术。

**(1) 存储在日志主记录中的 LSN 值为 00。它是最后一个有效 begin_checkpoint 记录编号。**

**(2) ARIES 分析阶段工作描述：**
**从 LSN00 开始向前扫描。**
*   遇到 LSN 20：添加 (T1, 20, 'U') 到 T.T.；添加 (P1, 20) 到 D.P.T；
*   遇到 LSN 30：添加 (T2, 30, 'U') 到 T.T.；添加 (P2, 30) 到 D.P.T；
*   遇到 LSN 40：添加 (T3, 40, 'U') 到 T.T.；添加 (P3, 40) 到 D.P.T；
*   遇到 LSN 50：修改 T.T. 表中的 (T2, 30, 'U') 为 (T2, 30, 'C')；
*   遇到 LSN 60：修改 T.T. 表中的 (T3, 40, 'U') 为 (T3, 60, 'U')；
*   遇到 LSN 70：删除 T.T. 表中的 (T2, 30, 'C')；
*   遇到 LSN 80：修改 T.T. 表中的 (T1, 20, 'U') 为 (T1, 80, 'U')；添加 (P5, 80) 到 D.P.T；
*   遇到 LSN 90：无动作；

**事务表 (T.T.)**：(T1, 80, 'U')(T3, 60, 'U')
**脏页表 (D.P.T.)**：(P1, 20)(P2, 30)(P3, 40)(P5, 80)

**REDO 阶段的工作描述：从脏页表中最小的记录即 LSN20 开始向前扫描处理，**
*   遇到 LSN 20：从磁盘检查 P1，比较 pageLSN 与 LSN20：
    *   If pageLSN < LSN20 then 利用 LSN20 旧值：redo P1; End if;
*   遇到 LSN 30：利用 LSN30 旧值，redo P2；
*   遇到 LSN 40：利用 LSN40 旧值，redo P3；
*   遇到 LSN 50：无动作；
*   遇到 LSN 60：无动作；
*   遇到 LSN 70：无动作；
*   遇到 LSN 80：利用 LSN80 旧值，redo P5；
*   遇到 LSN 90：无动作；

**UNDO 阶段的工作描述：从事务表中最大（后）的那条记录，即 LSN 80 开始处理，**
*   开始时，丢失事务集为 `{80, 60}`。
*   处理 LSN 80：根据事务 prevLSN 字段，增加 LSN20 到丢失事务集。
    *   undo 对 P5 的修改，增加 CLR 记录到日志尾。
    *   —— 丢失事务集变为：`{60, 20}`
*   处理 LSN 60：undo 对 P2 的修改，增加 CLR 记录到日志尾。
    *   —— 丢失事务集变为：`{40, 20}`
*   处理 LSN 40：undo 对 P3 的修改，增加 CLR 记录到日志尾。
    *   —— 丢失事务集变为：`{20}`
*   处理 LSN 20：undo 对 P1 的修改，增加 CLR 记录到日志尾。
    *   —— 丢失事务集变为：`{null}` — 处理结束。

**(3) 解释最终的日志长什么样**：把 Undo 阶段发生的事情写出来。

1.  **Analysis 阶段结论**：输家是 T1 和 T3。
2.  **Undo 开始倒着走**：
    *   日志最后是 LSN 90 (T3 Abort)。
    *   **第一步**：遇到 T1。T1 的最后一条有效记录是 LSN 80。
        *   动作：撤销 LSN 80。
        *   写日志：**LSN 100 (CLR for T1 LSN 80)**。
        *   `undonextLSN`：LSN 80 的上一条是 20，所以填 **20**。
    *   **第二步**：遇到 T3。T3 的最后一条有效记录是 LSN 60。
        *   动作：撤销 LSN 60。
        *   写日志：**LSN 110 (CLR for T3 LSN 60)**。
        *   `undonextLSN`：LSN 60 的上一条是 40，所以填 **40**。
    *   **第三步**：继续倒查。下一个还没撤销的是 T3 的 LSN 40。
        *   动作：撤销 LSN 40。
        *   写日志：**LSN 120 (CLR for T3 LSN 40)**。
        *   `undonextLSN`：LSN 40 的上一条是啥？图上没画，假设 T3 开始了，所以是 End。
    *   **第四步**：继续倒查。下一个还没撤销的是 T1 的 LSN 20（因为 LSN 80 已经被 LSN 100 搞定了，undonext 指向了 20）。
        *   动作：撤销 LSN 20。
        *   写日志：**LSN 130 (CLR for T1 LSN 20)**。

**(4) 如果反复崩溃，日志最多有多少条？(2n条原理)**

*   **问题背景**：
    假设系统有 `n` 条更新日志（比如 T1 改了 n 次）。现在系统崩了。重启恢复时，需要撤销这 n 次修改。
    但是在撤销的过程中，**每撤销一条，就得写一条 CLR**。
    如果撤销了一半又崩了，重启后继续撤销……会不会陷入死循环导致日志无限增加？

*   **答案逻辑**：
    **不会无限增加**。因为 ARIES 算法很聪明。
    *   **正常撤销**：你 undo 一条 Update，就写一条 CLR。CLR 里有个 `undonextLSN` 指针，指向“上一条还没撤销的”。
    *   **再次崩溃**：如果撤销了一半崩了。下次重启时，系统看到 CLR，会说：“哦，这条已经撤销过了，我直接看它的 `undonextLSN` 跳过它，去撤销更早的。”
    *   **结论**：因为**永远不会撤销“撤销记录(CLR)”本身**，所以每一个原始 Update 最多只会被对应生成一条 CLR。
    *   **算术题**：
        *   原始日志：`n` 条。
        *   对应的撤销日志 (CLR)：最多 `n` 条。
        *   总共：`n + n = 2n` 条。

**(5) 为什么 begin 和 end checkpoint 之间还有别的日志？**
**动态/模糊检查点**：大家继续跑，你拿着全景相机从左扫到右。
    *   当你按下快门开始（`begin_checkpoint`）到拍完结束（`end_checkpoint`）这段时间，由于大家还在跑，肯定会有人做了新动作（新的日志写入）。

*   **分析阶段怎么处理这些“乱入”的日志？**
    1.  从 `begin_checkpoint` 开始扫描。
    2.  读到 `end_checkpoint`：拿到一张“由于有人移动而稍微有点模糊”的底片（事务表和脏页表）。这张表反映的是 `begin` 时刻的状态。
    3.  **关键动作**：因为 `begin` 到 `end` 之间有人动了（有新日志），分析器会继续往后扫描，**把这些新变化补到刚才那张底片上**。
    4.  比如：底片上写着 T1 在睡觉。但在 `begin` 和 `end` 之间扫到一条日志“T1 起床了”。分析器就会把 T1 的状态改成“起床”。

**(6) end_checkpoint 记录了什么？**

*   **答案**：
    它记录的是在 **`begin_checkpoint` 那一瞬间**（按下快门那一刻）系统的状态快照。
    主要包含两样东西：
    1.  **事务表 (Transaction Table)**：当时谁还活着？
    2.  **脏页表 (Dirty Page Table)**：当时哪些页是脏的？

    *注*：虽然它是在 end 时刻才写完的，但它记录的数据内容基准是 begin 时刻的（或者结合 begin 到 end 之间的变化，视具体实现而定，但在 ARIES 标准理论中，通常我们认为它是 begin 时刻状态的一个锚点，分析阶段会负责修正）。根据标准答案的描述：“我们只能假设脏页表和事务表都是空表”，这是针对图 9.9(b) 这种特定上下文（可能之前没有任何活动）。但在通用理论中，它存的就是 TT 和 DPT。

| LSN | 图9.9(a)| 图9.9(b) |
| :---: | :--- | :--- |
| **00** | begin_checkpoint | begin_checkpoint |
| **10** | end_checkpoint | update: T1 writes P1 |
| **20** | update: T1 writes P1 | T1 commit |
| **30** | update: T2 writes P2 | update: T2 writes P2 |
| **40** | update: T3 writes P3 | T1 end |
| **50** | T2 commit | T2 abort |
| **60** | update: T3 writes P2 | update: T3 writes P2 |
| **70** | T2 end | end_checkpoint |
| **80** | update: T1 writes P5 | T3 commit |
| **90** | T3 abort | — |
| **状态** | **CRASH, RESTART** | **CRASH, RESTART** |